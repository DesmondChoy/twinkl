# Claude Synthetic Journal Generation Instructions

Instructions for Claude Code to generate synthetic conversational journal data using parallel subagents.

**No API keys required** - this uses Claude Code's native Task tool, not the external Claude Agent SDK.

**This is the primary method for generating synthetic data at scale.** The Jupyter notebooks (`notebooks/journal_gen.ipynb`, `notebooks/journal_nudge.ipynb`) are for experimentation and prompt iteration only.

---

## Configuration Variables

**Change these values to customize the generation run:**

| Variable | Default | Description |
|----------|---------|-------------|
| `NUM_PERSONAS` | 5 | Number of personas to generate |
| `MIN_ENTRIES` | 2 | Minimum entries per persona (supports cold-start scenarios) |
| `MAX_ENTRIES` | 12 | Maximum entries per persona (covers rut detection window) |
| `START_DATE` | Random in 2025 | Random date from 2025-01-01 to 2025-12-31 |
| `MIN_DAYS_BETWEEN_ENTRIES` | 0 | Minimum days between entries (0 = same-day allowed) |
| `MAX_DAYS_BETWEEN_ENTRIES` | 7 | Maximum days between entries (ensures ~1 entry/week) |
| `SAME_DAY_PROBABILITY` | 0.15 | Probability of same-day follow-up entry (15%) |
| `NUDGE_ENABLED` | true | Set to false to disable all nudge generation |

---

## Output Structure

**Flat directory with UUID-based filenames** (no timestamp subfolders):

```
logs/
├── registry/
│   └── personas.parquet              # Central tracking - source of truth
│
└── synthetic_data/
    ├── persona_a3f8b2c1.md           # UUID in filename (globally unique)
    ├── persona_e7d4f9a2.md
    └── ...                           # All personas in one folder
```

**Why flat structure?**
- UUID filenames are globally unique — no collision across batches
- Simpler paths for scripting and querying
- Batch grouping tracked in registry, not folder names

**Persona ID Format:**
- 8-character UUID (e.g., "a3f8b2c1")
- Generated by subagent: `python3 -c "import uuid; print(uuid.uuid4().hex[:8])"`
- Used directly in filename: `persona_{uuid}.md`

---

## Source Files

All prompts, decision logic, and configuration come from these files:

| File | Contains |
|------|----------|
| `config/synthetic_data.yaml` | Persona attributes, journal entry options, nudge settings |
| `config/schwartz_values.yaml` | Value elaborations for persona generation |
| `prompts/` | YAML prompt templates with Jinja2 |
| `notebooks/journal_nudge.ipynb` | Nudge decision logic, banned terms |

### Prompt Templates

Prompts are stored in `prompts/` as YAML files with embedded Jinja2 templates:

| File | Purpose |
|------|---------|
| `prompts/persona_generation.yaml` | Template for creating personas |
| `prompts/journal_entry.yaml` | Template for journal entries |
| `prompts/nudge_decision.yaml` | Template for LLM-based nudge classification |
| `prompts/nudge_generation.yaml` | Template for generating nudges |
| `prompts/nudge_response.yaml` | Template for persona responses |

### Notebook References

| Variable | Purpose |
|----------|---------|
| `SCHWARTZ_BANNED_TERMS` | Terms that must not appear in output |
| `decide_nudge_llm()` | LLM-based nudge decision logic |

---

## Execution Architecture

### Per-Persona Subagents (Parallel)

Each persona is handled by a single subagent that:
1. Generates its own UUID (globally unique across all batches)
2. Runs the full pipeline (entries + nudges + responses)
3. Writes its log file with UUID in filename
4. Registers itself in the central registry

All persona subagents run in parallel.

```
┌─────────────────────────────────────────────────────────────────────┐
│  MAIN ORCHESTRATOR (you)                                            │
│                                                                     │
│  0. Ensure directories exist: logs/synthetic_data/, logs/registry/  │
│                                                                     │
│  1. Launch all persona subagents with run_in_background=true        │
│     ┌────────────────┐ ┌────────────────┐ ┌────────────────┐       │
│     │ Persona        │ │ Persona        │ │ Persona        │       │
│     │ UUID: a3f8b2c1 │ │ UUID: e7d4f9a2 │ │ UUID: c1b5e8d3 │       │
│     │ Entry1→Nudge1  │ │ Entry1→Nudge1  │ │ Entry1→Nudge1  │       │
│     │ Entry2→Nudge2  │ │ Entry2→Nudge2  │ │ Entry2→Nudge2  │       │
│     │ ...→Write Log  │ │ ...→Write Log  │ │ ...→Write Log  │       │
│     │ →Register      │ │ →Register      │ │ →Register      │       │
│     └───────┬────────┘ └───────┬────────┘ └───────┬────────┘       │
│             │                  │                  │                 │
│  2. Wait for all to complete with TaskOutput                        │
│             │                  │                  │                 │
│             ▼                  ▼                  ▼                 │
│  3. Collect summaries, report results                               │
└─────────────────────────────────────────────────────────────────────┘
```

**Key insight**: Each subagent handles one persona's full pipeline **and registers it in the central registry**. No timestamp folders needed — UUIDs guarantee uniqueness across all batches.

---

## Claude Code Tools Used

### Orchestrator Tools

| Tool | Purpose |
|------|---------|
| `Task` | Spawn one subagent per persona (handles full pipeline + logging) |
| `TaskOutput` | Retrieve results from background tasks |
| `Write` | Create config.md log file |
| `Read` | Read source config files |
| `Bash` | Create log directory, generate random persona configs |

### Subagent Tools

| Tool | Purpose |
|------|---------|
| `Bash` | Random decisions (tone, verbosity, nudge gates, response probability) |
| `Write` | Write persona_XXX.md log file (parallel with other subagents) |

### Task Tool Parameters

```
Task tool call:
- description: "Persona N: Full pipeline"
- prompt: [persona config + all parameters + rules]
- subagent_type: "general-purpose"
- run_in_background: true  ← launches without blocking
```

### TaskOutput Tool Parameters

```
TaskOutput tool call:
- task_id: [ID returned from Task]
- block: true   ← waits for completion
- timeout: 300000  ← 5 minutes (full pipeline takes longer)
```

---

## Execution Steps

### 1. Read Source Files

Read and internalize:
- Both config YAML files
- The prompt templates from `prompts/` folder (including `nudge_decision.yaml` for LLM-based nudge classification)
- The `decide_nudge_llm()` function logic from `notebooks/journal_nudge.ipynb`
- **Extract `SCHWARTZ_BANNED_TERMS` list from notebook to embed in subagent prompts**

### 2. Ensure Directories Exist

Create the output directories if they don't exist:
```bash
mkdir -p logs/synthetic_data logs/registry
```

**Note:** No timestamp subfolders — all personas go in `logs/synthetic_data/` with UUID-based filenames.

### 3. Prepare Persona Configurations

For each of `{{NUM_PERSONAS}}` personas, randomly select:
- Age, profession, culture from `config/synthetic_data.yaml`
- 1-2 Schwartz values
- Look up value elaborations from `config/schwartz_values.yaml`
- **Entry count**: `random.randint({{MIN_ENTRIES}}, {{MAX_ENTRIES}})`
- **Start date**: Random date in 2025 (not fixed)
- Generate dates for that persona's entry count using weighted gap probability

**Random Selection via Bash** (for true randomness):
```bash
# Select random age bracket
python3 -c "import random; print(random.choice(['18-24', '25-34', '35-44', '45-54', '55+']))"

# Select random profession (read actual list from config)
python3 -c "import random; print(random.choice(['Teacher', 'Engineer', 'Nurse', 'Artist', ...]))"

# Select 1-2 Schwartz values
python3 -c "import random; vals=['Self-Direction','Stimulation','Hedonism','Achievement','Power','Security','Conformity','Tradition','Benevolence','Universalism']; k=random.randint(1,2); print(random.sample(vals,k))"

# Select random entry count for this persona
python3 -c "import random; print(random.randint({{MIN_ENTRIES}}, {{MAX_ENTRIES}}))"
```

**Random Start Date Generation via Bash**:
```bash
# Generate random start date anywhere in 2025
python3 -c "
import random
from datetime import date, timedelta
year_start = date(2025, 1, 1)
days_in_year = 364  # 0-364 gives full year coverage
random_offset = random.randint(0, days_in_year)
start_date = year_start + timedelta(days=random_offset)
print(start_date.isoformat())
"
```

**Date Gap Generation via Bash** (with same-day probability):
```bash
# Generate gap with 15% chance of same-day follow-up
python3 -c "
import random
SAME_DAY_PROB = {{SAME_DAY_PROBABILITY}}  # Default: 0.15
MAX_GAP = {{MAX_DAYS_BETWEEN_ENTRIES}}    # Default: 7
if random.random() < SAME_DAY_PROB:
    print(0)  # Same day
else:
    print(random.randint(1, MAX_GAP))  # 1 to MAX_GAP days
"
```

**Why same-day entries?** Real journaling apps see ~15% of active users making same-day follow-ups (morning reflection + evening venting, urgent emotional events). This gives the VIF exposure to rapid Δt=0 sequences without overwhelming the data.

Example for a persona with 5 entries starting 2025-03-15 (random):
- Entry 1: 2025-03-15 (random START_DATE)
- Gap 1: weighted random → 4 days (normal gap)
- Entry 2: 2025-03-19
- Gap 2: weighted random → 0 days (same-day follow-up, 15% probability)
- Entry 3: 2025-03-19 (same day as Entry 2)
- Gap 3: weighted random → 6 days
- Entry 4: 2025-03-25
- Gap 4: weighted random → 2 days
- Entry 5: 2025-03-27

### 4. Launch All Persona Subagents

Send **one message** with `{{NUM_PERSONAS}}` Task tool calls, all with `run_in_background=true`:

```
Tool: Task
- description: "Persona 1: Full pipeline"
- subagent_type: "general-purpose"
- run_in_background: true
- prompt: [Full persona prompt - see below]

Tool: Task
- description: "Persona 2: Full pipeline"
- subagent_type: "general-purpose"
- run_in_background: true
- prompt: [Full persona prompt - see below]

... (all {{NUM_PERSONAS}} in one message)
```

Each Task returns immediately with a `task_id`. The subagent handles the full pipeline internally.

### 5. Wait for All Subagents

Use TaskOutput to wait for each persona to complete:

```
Tool: TaskOutput
- task_id: [persona 1 task ID]
- block: true
- timeout: 300000

Tool: TaskOutput
- task_id: [persona 2 task ID]
- block: true
- timeout: 300000

... (can poll multiple in parallel)
```

### 6. Persona Pipeline Subagent Prompt

Each subagent receives everything needed to generate a complete persona with all entries, **write its own log file**, and **register in the central registry**.

**Input to subagent:**

1. **Persona constraints** (randomly selected by orchestrator):
   - Age, profession, culture from `config/synthetic_data.yaml`
   - 1-2 Schwartz values
   - Value elaborations from `config/schwartz_values.yaml`

2. **Entry dates**: All dates for this persona (count varies per persona, pre-generated by orchestrator)
   - Start date is random within 2025 (not fixed)
   - Gaps use weighted probability: 15% same-day, 85% normal (1-7 days)
   - Same-day entries may occur (Δt = 0)

3. **Generation parameters**:
   - Tone, verbosity, reflection_mode options from config
   - Banned terms extracted from notebook and embedded in this prompt
   - Prompt templates from `prompts/` folder

4. **Nudge rules**:
   - `NUDGE_ENABLED` variable (if false, skip all nudge logic)
   - `decide_nudge_llm()` logic from notebook (LLM-based classification)
   - `prompts/nudge_decision.yaml` for semantic entry classification
   - Nudge generation instructions from `prompts/nudge_generation.yaml`

5. **Response parameters**:
   - `response_probability` from config
   - `response_modes` with weights from config
   - Response generation instructions from `prompts/nudge_response.yaml`

6. **Output parameters**:
   - Output directory: `logs/synthetic_data/` (flat, no timestamp subfolder)
   - Registry module instructions for registration

**Subagent internal loop:**

```
0. Generate UUID for this persona:
   python3 -c "import uuid; print(uuid.uuid4().hex[:8])"
   → Store as persona_id (e.g., "a3f8b2c1")

1. Generate persona (name, bio based on constraints)

For each entry date:
  2. Randomly select tone/verbosity/reflection_mode
  3. Generate entry content (with accumulated context from prior entries)
     - Note: Same-day entries (Δt=0) should reflect continued thought/venting, not restart
  4. Check NUDGE_ENABLED:
     - If false → Output ONLY `*(No nudge for this entry)*`, skip to step 10
  5. Check session cap (2+ nudges in last 3 entries → skip to step 10 with no_nudge)
  6. Classify entry using nudge_decision_prompt criteria:
     - If "no_nudge" → Output ONLY `*(No nudge for this entry)*`, skip to step 10
     - Otherwise → Continue to step 7
  7. Generate `### Nudge (category)` section with `**Trigger**:` line and quoted nudge text
  8. Run Bash for response decision:
     python3 -c "import random; print(random.random() < [response_probability])"
  9. Based on Bash result:
     - If "True" → Generate `### Response` section with `**Mode**:` line and response text
     - If "False" → Output ONLY `*(No response - persona did not reply to nudge)*` (NO Response section)
  10. Store entry result, continue to next date

11. Write persona_{uuid}.md log file using Write tool
12. Register persona in registry using Bash:
    python3 -c "
    from src.registry import register_persona
    register_persona(
        persona_id='[uuid]',
        name='[name]',
        age='[age]',
        profession='[profession]',
        culture='[culture]',
        core_values=[core_values],
        entry_count=[entry_count],
        nudge_enabled=[NUDGE_ENABLED],  # True or False from config
    )
    print('Registered persona [uuid]')
    "
13. Return summary JSON with persona_id + name + stats (for orchestrator report)
```

**Note on LLM Classification**: The subagent itself (Claude) performs the nudge classification internally using the `nudge_decision.yaml` template as guidance. No external API call is needed—the subagent evaluates the entry against the classification criteria and returns the appropriate category.

**Bash-Based Randomness:**
LLMs cannot generate true randomness. The subagent MUST use the Bash tool for probabilistic decisions:
```bash
python3 -c "import random; print(random.random() < 0.7)"
```
If output is `True`: Generate response. If `False`: Set `response: null`.

**Subagent writes log file using Write tool:**

The subagent uses the Write tool to create `persona_{uuid}.md` in the output directory:
```
Write tool call:
- file_path: logs/synthetic_data/persona_a3f8b2c1.md
- content: [formatted markdown - see format below]
```

---

## Output File Format Specification (MANDATORY)

This section specifies the **exact format** for persona markdown files. Subagents MUST follow this specification precisely — any deviation will cause parsing failures downstream.

### Why This Matters

The downstream parser (`src/wrangling/parse_synthetic_data.py`) uses **exact string matching** for markers and **regex patterns** for sections. Variations in formatting — different section names, JSON instead of bullets, tables instead of lists — will cause silent parsing failures.

### Format Rules (10 total)

Each rule shows the CORRECT format with an example, followed by INCORRECT alternatives to avoid.

---

#### Rule 1: File Header

**CORRECT:**
```markdown
# Persona a3f8b2c1: Gabriela Mendoza
```

**INCORRECT (do NOT use):**
```markdown
# Persona: Gabriela Mendoza           ← Missing UUID
# Persona a3f8b2c1 - Gabriela Mendoza ← Wrong separator (dash instead of colon)
# persona a3f8b2c1: Gabriela Mendoza  ← Lowercase "persona"
## Persona a3f8b2c1: Gabriela Mendoza ← Wrong header level
```

---

#### Rule 2: Profile Section

**CORRECT:** Bullet list with specific field format (note: Age/Profession/Culture without bold, Bio with bold):
```markdown
## Profile
- **Persona ID:** a3f8b2c1
- **Generated:** 2026-01-16_14-30-00
- Age: 25-34
- Profession: Software Engineer
- Culture: Brazilian
- Core Values: Achievement, Self-Direction
- Bio: Gabriela is a backend developer at a São Paulo fintech startup. She immigrated from a small town in Minas Gerais and often reflects on how her career ambitions affect her relationship with her family back home.
```

**INCORRECT (do NOT use):**
```json
{
  "persona_id": "a3f8b2c1",
  "age": "25-34"
}
```
← No JSON format

```markdown
| Field | Value |
|-------|-------|
| Age   | 25-34 |
```
← No tables for profile

```markdown
- **Age:** 25-34
```
← Age/Profession/Culture fields MUST NOT have bold on field name

---

#### Rule 3: Entry Header

**CORRECT:**
```markdown
## Entry 1 - 2025-12-01
```

**INCORRECT (do NOT use):**
```markdown
### Entry 1 - 2025-12-01     ← Wrong header level (### instead of ##)
## Entry 1: 2025-12-01       ← Wrong separator (colon instead of dash)
## Entry 1 — 2025-12-01      ← Wrong dash (em-dash instead of hyphen)
## Entry 1 - December 1      ← Wrong date format (must be YYYY-MM-DD)
## Day 1 - 2025-12-01        ← Wrong label (must be "Entry")
```

---

#### Rule 4: Initial Entry Section

**CORRECT:**
```markdown
### Initial Entry
**Tone**: reflective | **Verbosity**: medium | **Reflection Mode**: exploratory

Today I had a difficult conversation with my manager about the promotion timeline...
```

**INCORRECT (do NOT use):**
```markdown
### Journal Entry            ← Wrong section name (must be "Initial Entry")
### Entry Content            ← Wrong section name
### Initial entry            ← Wrong capitalization

**Tone**: reflective
**Verbosity**: medium        ← Wrong: metadata MUST be on single line with pipe separators
**Reflection Mode**: exploratory
```

---

#### Rule 5: Nudge Section (when nudge exists)

**CORRECT:**
```markdown
### Nudge (elaboration)
**Trigger**: Entry mentions career uncertainty without exploring underlying fears
"What specifically about the promotion timeline feels uncertain? Is it the timing itself, or something about what the promotion would mean for you?"
```

**INCORRECT (do NOT use):**
```markdown
### Nudge                    ← Missing category in parentheses
### Nudge: elaboration       ← Colon instead of parentheses for category
### Nudge (Elaboration)      ← Category should be lowercase

**Trigger**: Entry mentions career uncertainty
What specifically about the promotion timeline feels uncertain?
                             ← Nudge text MUST be in double quotes
```

---

#### Rule 6: No Nudge Marker

**CORRECT:** (use this EXACT text, including asterisks and parentheses)
```markdown
*(No nudge for this entry)*
```

**INCORRECT (do NOT use):**
```markdown
*No nudge for this entry*    ← Missing parentheses
(No nudge for this entry)    ← Missing asterisks
**No nudge for this entry**  ← Wrong emphasis markers
No nudge generated           ← Completely different text
### No Nudge                 ← Do not use a section header for no-nudge
```

**CRITICAL: `no_nudge` is a classification, not a section type.**

When the LLM classifies an entry as `no_nudge`:
- Do NOT create a `### Nudge` section
- Do NOT include a `**Trigger**:` line
- Output ONLY the marker: `*(No nudge for this entry)*`

The marker appears directly after the Initial Entry content, with no section header preceding it.

**INCORRECT (never do this):**
```markdown
### Nudge (no_nudge)
**Trigger**: Entry is complete and grounded
*(No nudge for this entry)*
```

---

#### Rule 7: Response Section (when response exists)

**CORRECT:**
```markdown
### Response
**Mode**: Answering directly

It's not just the timing — I think I'm worried that if I get promoted, I'll have even less time for my family. My mom has been hinting about visiting, and I keep pushing it off because of work deadlines.
```

**INCORRECT (do NOT use):**
```markdown
### User Response            ← Wrong section name (must be "Response")
### Persona Response         ← Wrong section name

**Mode**: answering directly ← Mode value should match config exactly (capitalized)

### Response
It's not just the timing... ← Missing **Mode**: line
```

---

#### Rule 8: No Response Marker

**CORRECT:** (use this EXACT text, including asterisks and parentheses)
```markdown
*(No response - persona did not reply to nudge)*
```

**INCORRECT (do NOT use):**
```markdown
*(No response)*              ← Too short, missing explanation
*(Persona did not respond)*  ← Different text
*No response - persona did not reply to nudge*  ← Missing outer parentheses
**No response**              ← Wrong format entirely
```

**CRITICAL: When Nudge Exists But No Response**

When a nudge IS generated but the random response decision returns False:
- Do NOT create a `### Response` section
- Do NOT include a `**Mode**:` line
- The no-response marker appears immediately after the quoted nudge text (with a blank line separator)

**CORRECT:**
```markdown
### Nudge (elaboration)
**Trigger**: Entry hints at deeper meaning
"What would that have looked like?"

*(No response - persona did not reply to nudge)*
```

**INCORRECT (never do this):**
```markdown
### Nudge (elaboration)
**Trigger**: Entry hints at deeper meaning
"What would that have looked like?"

### Response
**Mode**: None

*(No response - persona did not reply to nudge)*
```

---

#### Rule 9: Entry Separator

**CORRECT:** Three hyphens on their own line after each entry
```markdown
---
```

**INCORRECT (do NOT use):**
```markdown
***                          ← Wrong character
===                          ← Wrong character
----                         ← Too many hyphens
```

---

#### Rule 10: Summary Statistics Section

**CORRECT:**
```markdown
## Summary Statistics
| Metric | Value |
|--------|-------|
| Total Entries | 5 |
| Nudges Generated | 3 |
| Responses Given | 2 |
| Nudge Categories | clarification (1), elaboration (1), tension_surfacing (1) |
| Response Modes | Answering directly (1), Revealing deeper (1) |
```

**INCORRECT (do NOT use):**
```markdown
## Stats                     ← Wrong section name
## Summary                   ← Wrong section name
### Summary Statistics       ← Wrong header level

- Total Entries: 5           ← Must be a table, not bullet list
- Nudges Generated: 3
```

---

### Complete Example File

Below is a **complete example** showing all edge cases: entries with nudge + response, nudge + no response, and no nudge.

```markdown
# Persona a3f8b2c1: Gabriela Mendoza

## Profile
- **Persona ID:** a3f8b2c1
- **Generated:** 2026-01-16_14-30-00
- Age: 25-34
- Profession: Software Engineer
- Culture: Brazilian
- Core Values: Achievement, Self-Direction
- Bio: Gabriela is a backend developer at a São Paulo fintech startup. She immigrated from a small town in Minas Gerais and often reflects on how her career ambitions affect her relationship with her family back home.

---

## Entry 1 - 2025-12-01

### Initial Entry
**Tone**: reflective | **Verbosity**: medium | **Reflection Mode**: exploratory

Today I had a difficult conversation with my manager about the promotion timeline. He said I'm "on track" but couldn't give me a specific date. I left the meeting feeling unsettled — not sure if I should push harder or just keep my head down and wait.

### Nudge (elaboration)
**Trigger**: Entry mentions career uncertainty without exploring underlying fears
"What specifically about the promotion timeline feels uncertain? Is it the timing itself, or something about what the promotion would mean for you?"

### Response
**Mode**: Answering directly

It's not just the timing — I think I'm worried that if I get promoted, I'll have even less time for my family. My mom has been hinting about visiting, and I keep pushing it off because of work deadlines.

---

## Entry 2 - 2025-12-06

### Initial Entry
**Tone**: frustrated | **Verbosity**: short | **Reflection Mode**: venting

Bad day. The deploy failed at 3 AM and I had to roll back manually. Spent most of today debugging instead of working on my actual project.

*(No nudge for this entry)*

---

## Entry 3 - 2025-12-09

### Initial Entry
**Tone**: hopeful | **Verbosity**: long | **Reflection Mode**: planning

I've been thinking a lot about what I said about my mom visiting. I looked at my calendar and realized I've been treating "busy" as my default excuse for everything. What if I actually blocked off two weeks in February and told work in advance? The worst they can say is no, and at least then I'd know where I stand.

I also started wondering if my reluctance to take time off is really about work, or if it's something else. Maybe I'm nervous about having her here and seeing how different my life is now. I left home to pursue this career, and sometimes I wonder if she thinks I abandoned the family.

### Nudge (tension_surfacing)
**Trigger**: Entry hints at unresolved conflict between career identity and family expectations
"You mentioned wondering if your mom thinks you abandoned the family. Has she ever said anything that gave you that impression, or is this more of an internal worry?"

*(No response - persona did not reply to nudge)*

---

## Entry 4 - 2025-12-14

### Initial Entry
**Tone**: neutral | **Verbosity**: medium | **Reflection Mode**: reporting

Weekly update: finished the API refactor, started documentation. Team lunch on Friday was nice — we tried that new ramen place downtown. Looking forward to the holiday break coming up.

*(No nudge for this entry)*

---

## Entry 5 - 2025-12-20

### Initial Entry
**Tone**: reflective | **Verbosity**: medium | **Reflection Mode**: exploratory

I finally texted my mom about February. She called me immediately — I could hear how happy she was. We talked for almost an hour, the longest conversation we've had in months. She didn't mention anything about me leaving or being too busy. She just wanted to know what my apartment looks like and if I'm eating well.

I think I was projecting a lot onto her. She's proud of me. The distance I was feeling was something I built, not something she created.

### Nudge (clarification)
**Trigger**: Entry makes a significant realization but attribution is vague ("I think I was projecting")
"When you say you were 'projecting' onto your mom — what specifically were you imagining she thought or felt that turned out not to be true?"

### Response
**Mode**: Revealing deeper

I assumed she was disappointed that I moved so far away and chose work over family time. But when I actually talked to her, she said she brags about me to her friends all the time. She kept my old bedroom exactly as I left it, not as a guilt trip, but because she likes remembering me as a teenager with big dreams. I had built this whole narrative in my head that she resented my choices, but she was just missing me, the same way I miss her.

---

## Summary Statistics
| Metric | Value |
|--------|-------|
| Total Entries | 5 |
| Nudges Generated | 3 |
| Responses Given | 2 |
| Nudge Categories | clarification (1), elaboration (1), tension_surfacing (1) |
| Response Modes | Answering directly (1), Revealing deeper (1) |
```

---

### Output Format by Decision State

This table summarizes the exact output format for each combination of nudge classification and response decision:

| Entry Classification | Response Decision | Output Format |
|---------------------|-------------------|---------------|
| `no_nudge` | N/A (no nudge = no response check) | `*(No nudge for this entry)*` only — NO Nudge section |
| `clarification` / `elaboration` / `tension_surfacing` | True | `### Nudge (category)` section + `### Response` section |
| `clarification` / `elaboration` / `tension_surfacing` | False | `### Nudge (category)` section + `*(No response - persona did not reply to nudge)*` marker only — NO Response section |

**Key principle:** Classifications map to output presence, not section content. If a section shouldn't exist for a given state, it must be completely absent — not present with special values like "None" or "no_nudge".

---

### Validation Checklist (14 points)

Before writing the log file, verify ALL of the following:

**File Structure:**
- [ ] 1. Header is `# Persona {uuid}: {Name}` (exact format, colon separator)
- [ ] 2. Profile section uses bullet list with correct field names (not JSON, not table)
- [ ] 3. Profile fields Age/Profession/Culture do NOT have bold field names
- [ ] 4. Bio field starts with `- Bio:` (single line marker, content can wrap)

**Entry Structure:**
- [ ] 5. Each entry header is `## Entry N - YYYY-MM-DD` (exact format, hyphen separator)
- [ ] 6. Each entry has `### Initial Entry` section (not "Journal Entry")
- [ ] 7. Metadata line format is `**Tone**: X | **Verbosity**: Y | **Reflection Mode**: Z` (single line, pipe separated)

**Nudge/Response Handling:**
- [ ] 8. Nudge section (if exists) is `### Nudge (category)` with lowercase category
- [ ] 9. Nudge text is wrapped in double quotes
- [ ] 10. If no nudge: ONLY the marker `*(No nudge for this entry)*` appears (NO Nudge section)
- [ ] 11. If nudge + response: `### Response` section with `**Mode**: X` line exists
- [ ] 12. If nudge + no response: ONLY the marker `*(No response - persona did not reply to nudge)*` appears (NO Response section)

**Separators & Summary:**
- [ ] 13. Each entry ends with `---` separator
- [ ] 14. Summary section is `## Summary Statistics` with pipe-formatted table

**Forbidden:**
- [ ] No JSON blocks anywhere in the file
- [ ] No debug output or status messages
- [ ] No commentary or explanatory text outside the specified structure

**Output format (summary JSON from subagent for orchestrator):**

After writing the log file and registering in the registry, subagent returns a lightweight summary:
```json
{
  "persona_id": "a3f8b2c1",
  "persona_name": "Gabriela Mendoza",
  "log_file": "persona_a3f8b2c1.md",
  "stats": {
    "entries": 5,
    "nudges": 3,
    "responses": 2
  }
}
```

### 7. Collect Results & Report

The orchestrator collects summary JSONs from each subagent (the full data is already written to log files and registered in the registry).

### 8. Report Summary

Print:
- Personas generated: X/{{NUM_PERSONAS}}
- Entry count distribution: min=X, max=X, avg=X.X
- Total entries: X
- Total nudges: X
- Total responses: X (expect response_probability × nudges)
- Response rate: X% (should approximate response_probability from config)
- Registry status (from `src.registry.get_status()`)

**Query registry for summary:**
```python
from src.registry import get_status
status = get_status()
print(f"Total in registry: {status['total']}")
print(f"Pending wrangling: {status['pending_wrangling']}")
```

---

## Quick Reference: Nudge Decision Tree

From `decide_nudge_llm()` in notebook — uses LLM classification instead of regex patterns:

```
0. NUDGE_ENABLED = false? → No nudge (disabled globally)
1. Session cap hit? (2+ nudges in last 3 entries) → No nudge (code-based policy)
2. LLM classifies entry into one of:
   - "no_nudge" — Entry is complete and grounded
   - "clarification" — Entry too vague to understand
   - "elaboration" — Solid entry with unexplored depth
   - "tension_surfacing" — Hints at unresolved conflict
```

The LLM prompt (`prompts/nudge_decision.yaml`) provides semantic criteria for each category, enabling detection of nuanced vagueness, hedging language, and tension that regex patterns would miss.

> **Note**: Grounding nudges were removed—they relied on `reflection_mode` metadata unavailable in production. See `pipeline_specs.md` for details.

**Response Decision (after nudge is generated):**
```
Nudge generated?
   │
   └─YES─→ Run Bash: python3 -c "import random; print(random.random() < [response_probability])"
              │
              ├─Output "True"─→ Generate response using weighted response_mode from config
              │
              └─Output "False"─→ No response (response: null)
```
Note: The orchestrator extracts `response_probability` from `config/synthetic_data.yaml` and embeds it in the subagent prompt.

---

## Optional: Define Custom Subagent

For cleaner organization, you can define a specialized persona pipeline subagent in `.claude/agents/`:

**`.claude/agents/persona-pipeline.md`**:
```markdown
---
name: persona-pipeline
description: Generates complete persona with all journal entries, nudges, responses, and writes log file
tools:
  - Bash
  - Write
---

You are a persona pipeline generator. Given persona constraints and parameters,
generate a complete persona with all journal entries and write the log file.

For each entry:
1. Generate entry content following style rules
2. Apply nudge decision logic
3. If nudging: generate nudge, then use Bash for random response decision
4. Accumulate context for next entry

After all entries:
5. Write persona_XXX.md log file using Write tool
6. Return summary JSON with stats

[Include full prompt templates and decide_nudge_llm() logic here]
```

Then invoke with `subagent_type: "persona-pipeline"` instead of `"general-purpose"`.

**Benefits of custom subagent:**
- Reusable across runs
- Cleaner prompts (instructions live in agent definition)
- Tool restrictions (only Bash for randomness + Write for logging)
- Parallel logging built into each subagent

---

## Checklist

- [ ] Read source files (configs + prompts/ + notebook)
- [ ] Set configuration variables above
- [ ] Ensure directories exist: `logs/synthetic_data/`, `logs/registry/`
- [ ] Prepare `{{NUM_PERSONAS}}` persona configurations (random selections including entry count)
- [ ] Launch all persona subagents with `run_in_background=true` in ONE message
  - Each subagent generates its own UUID
  - Each subagent writes `logs/synthetic_data/persona_{uuid}.md`
  - Each subagent registers itself in the registry
- [ ] Wait for all subagents to complete with `TaskOutput`
- [ ] Collect summary stats from each subagent
- [ ] Report summary (including registry status)

**Subagent count:** `{{NUM_PERSONAS}}` total (one per persona)

**Example:** 5 personas = 5 subagent calls (all run in parallel, each with unique UUID)

**Verify registration:**
```bash
python3 -c "from src.registry import get_status; print(get_status())"
```

---

## Limitations

- **Max 10 parallel personas**: Claude Code caps parallelism at 10; additional tasks queue automatically
- **Context isolation**: Each subagent has separate 200k context; pass all needed info in the prompt
- **Subagent timeout**: Set adequate timeout (5+ minutes) for full pipeline generation
