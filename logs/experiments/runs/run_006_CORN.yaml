# VIF Experiment: run_006_CORN
# Generated: 2026-02-20T09:27:37
# Git: 4c48773(dirty)
metadata:
  experiment_id: run_006_CORN
  run_id: run_006
  model_name: CORN
  timestamp: '2026-02-20T09:27:37'
  git_commit: 4c48773(dirty)
  config_hash: 10a66a987aea
provenance:
  prev_run_id: run_004
  prev_git_commit: a3f493f(dirty)
  git_log:
  - '4c48773 docs: remove redundant introductory sentences from AGENTS.md and GEMINI.md'
  - '31918e6 fix(vif): include dataset splits in experiment logger deduplication hash'
  - 'e5cb197 fix(vif): include dataset splits in experiment logger deduplication hash'
  - 'b84d1ca fix(judge): backfill rationales for 61 personas and fix under-labeled
    entry'
  - 'c0435e1 chore(data): add batch 2 judge labels for 60 new personas'
  - 'cd59d19 chore(data): add batch 2 synthetic and wrangled persona data (60 personas)'
  - '986e408 feat(judge): add consolidation module, harden wrangling parser, and update
    judge pipeline docs'
  - 'a036004 chore(data): remove batch 1A pre-tension Universalism personas (10)'
  - de4a5e1 Refactor notebook references to scripts and harden synthetic helpers (twinkl-ayp)
  - '62cbe11 docs(gen): fix config variables — remove dead START_DATE, wire MIN_DAYS_BETWEEN_ENTRIES'
  - '9e3e22a feat(vif): add runs 003/004 experiment logs with provenance backfill'
  config_delta:
    added:
      data.train_ratio: 0.7
      data.val_ratio: 0.15
      data.split_seed: 2025
      data.pct_truncated: 0.0
      data.state_dim: 266
      uncertainty.mc_dropout_samples: 50
    removed: {}
    changed: {}
  rationale: Re-run of nomic-embed-256d configuration with expanded dataset (958
    train vs 637). Added 60 new personas from batch 2, removed 10 pre-tension
    Universalism personas, and added MC dropout uncertainty (50 samples). Tests
    whether 50% more data improves nomic/small-model performance.
config:
  encoder:
    model_name: nomic-ai/nomic-embed-text-v1.5
    truncate_dim: 256
    text_prefix: 'classification: '
    trust_remote_code: true
  state_encoder:
    window_size: 1
  data:
    train_ratio: 0.7
    val_ratio: 0.15
    split_seed: 2025
    pct_truncated: 0.0
    state_dim: 266
  model:
    hidden_dim: 32
    dropout: 0.3
  training:
    loss_fn: corn
    learning_rate: 0.001
    weight_decay: 0.01
    batch_size: 16
    epochs: 100
    early_stopping_patience: 20
    scheduler_factor: 0.5
    scheduler_patience: 10
    seed: 2025
  uncertainty:
    mc_dropout_samples: 50
data:
  n_train: 958
  n_val: 214
  n_test: 202
capacity:
  n_parameters: 10388
  param_sample_ratio: 10.8434
training_dynamics:
  best_epoch: 29
  total_epochs: 49
  train_loss_at_best: 0.2493
  val_loss_at_best: 0.2996
  gap_at_best: 0.0503
  final_lr: 0.0005
evaluation:
  mae_mean: 0.2363
  accuracy_mean: 0.7911
  qwk_mean: 0.2797
  spearman_mean: 0.3505
  calibration_global: 0.7775
  calibration_positive_dims: 10
  mean_uncertainty: 0.1771
  minority_recall_mean: 0.1834
  recall_minus1: 0.0261
  recall_plus1: 0.3407
  hedging_mean: 0.8223
per_dimension:
  self_direction:
    mae: 0.3834
    accuracy: 0.6634
    qwk: 0.2696
    spearman: 0.2893
    calibration: 0.5895
    hedging: 0.6634
  stimulation:
    mae: 0.137
    accuracy: 0.8713
    qwk: 0.3396
    spearman: 0.5321
    calibration: 0.8123
    hedging: 0.8861
  hedonism:
    mae: 0.1394
    accuracy: 0.8762
    qwk: 0.3795
    spearman: 0.3289
    calibration: 0.8853
    hedging: 0.9208
  achievement:
    mae: 0.2902
    accuracy: 0.7327
    qwk: 0.3801
    spearman: 0.5057
    calibration: 0.7
    hedging: 0.5792
  power:
    mae: 0.1662
    accuracy: 0.8663
    qwk: -0.0144
    spearman: 0.141
    calibration: 0.7745
    hedging: 0.9455
  security:
    mae: 0.2454
    accuracy: 0.797
    qwk: 0.3138
    spearman: 0.3089
    calibration: 0.6523
    hedging: 0.8614
  conformity:
    mae: 0.2854
    accuracy: 0.7624
    qwk: 0.2951
    spearman: 0.2228
    calibration: 0.756
    hedging: 0.8366
  tradition:
    mae: 0.1998
    accuracy: 0.8267
    qwk: 0.2817
    spearman: 0.3072
    calibration: 0.7567
    hedging: 0.9208
  benevolence:
    mae: 0.325
    accuracy: 0.698
    qwk: 0.2855
    spearman: 0.4356
    calibration: 0.6247
    hedging: 0.7624
  universalism:
    mae: 0.191
    accuracy: 0.8168
    qwk: 0.2668
    spearman: 0.4332
    calibration: 0.8633
    hedging: 0.8465
observations: CORN with nomic on expanded data shows QWK 0.280 (comparable to
  run_004's 0.291). Power QWK turned negative (-0.014) — worse than random. Hedging
  (82.2%) is the lowest among run_006 losses, and calibration is the best at 0.778.
  Achievement improved to 0.380 (from 0.232). CORN no longer produces NaN QWK on
  hedonism with the larger dataset (0.380), suggesting the additional data resolved
  the degenerate-prediction failure mode for that dimension. Tradition remains weak
  (QWK 0.282).
