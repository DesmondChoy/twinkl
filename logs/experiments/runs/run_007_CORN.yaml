# VIF Experiment: run_007_CORN
# Generated: 2026-02-20T14:40:56
# Git: d0b93da(dirty)
metadata:
  experiment_id: run_007_CORN
  run_id: run_007
  model_name: CORN
  timestamp: '2026-02-20T14:40:56'
  git_commit: d0b93da(dirty)
  config_hash: a37bde71dd03
provenance:
  prev_run_id: run_006
  prev_git_commit: 4c48773(dirty)
  git_log:
  - 'd0b93da chore(judge): wrangle and label 10 Power personas (180/180 complete)'
  - '46004f9 docs: update GEMINI.md architecture snapshot and clarify ambiguities'
  - '0468ddf feat(synth): add Power tension scenarios to tension-selection skill'
  - '1831807 chore(vif): add experiment runs 007-008 and update training notebook'
  - '6118a22 chore(vif): add experiment runs 005-006 and update training notebooks'
  config_delta:
    added: {}
    removed: {}
    changed:
      model.hidden_dim:
        from: 32
        to: 64
  rationale: Doubled hidden_dim from 32 to 64 on nomic-embed-256d to test whether additional
    capacity improves QWK and minority recall. Dataset expanded to 1020 train with 10
    new Power tension personas (180/180 complete). Tests the capacity sweet spot between
    the compact hd=32 and the over-parameterized MiniLM hd=256.
config:
  encoder:
    model_name: nomic-ai/nomic-embed-text-v1.5
    truncate_dim: 256
    text_prefix: 'classification: '
    trust_remote_code: true
  state_encoder:
    window_size: 1
  data:
    train_ratio: 0.7
    val_ratio: 0.15
    split_seed: 2025
    pct_truncated: 0.0
    state_dim: 266
  model:
    hidden_dim: 64
    dropout: 0.3
  training:
    loss_fn: corn
    learning_rate: 0.001
    weight_decay: 0.01
    batch_size: 16
    epochs: 100
    early_stopping_patience: 20
    scheduler_factor: 0.5
    scheduler_patience: 10
    seed: 2025
  uncertainty:
    mc_dropout_samples: 50
data:
  n_train: 1020
  n_val: 230
  n_test: 210
capacity:
  n_parameters: 22804
  param_sample_ratio: 22.3569
training_dynamics:
  best_epoch: 16
  total_epochs: 36
  train_loss_at_best: 0.2249
  val_loss_at_best: 0.2318
  gap_at_best: 0.0069
  final_lr: 0.0005
evaluation:
  mae_mean: 0.2049
  accuracy_mean: 0.8205
  qwk_mean: 0.4132
  spearman_mean: 0.4018
  calibration_global: 0.8375
  calibration_positive_dims: 10
  mean_uncertainty: 0.149
  minority_recall_mean: 0.285
  recall_minus1: 0.1031
  recall_plus1: 0.4669
  hedging_mean: 0.8167
per_dimension:
  self_direction:
    mae: 0.4122
    accuracy: 0.6524
    qwk: 0.4292
    spearman: 0.4206
    calibration: 0.5181
    hedging: 0.5857
  stimulation:
    mae: 0.089
    accuracy: 0.919
    qwk: 0.5159
    spearman: 0.392
    calibration: 0.8801
    hedging: 0.9333
  hedonism:
    mae: 0.1334
    accuracy: 0.8905
    qwk: 0.4654
    spearman: 0.3141
    calibration: 0.9022
    hedging: 0.9048
  achievement:
    mae: 0.1626
    accuracy: 0.8524
    qwk: 0.3441
    spearman: 0.3249
    calibration: 0.7619
    hedging: 0.8667
  power:
    mae: 0.0557
    accuracy: 0.9524
    qwk: 0.3776
    spearman: 0.243
    calibration: 0.8999
    hedging: 0.9762
  security:
    mae: 0.3113
    accuracy: 0.719
    qwk: 0.1094
    spearman: 0.3053
    calibration: 0.7315
    hedging: 0.8619
  conformity:
    mae: 0.2666
    accuracy: 0.7571
    qwk: 0.5353
    spearman: 0.5259
    calibration: 0.7324
    hedging: 0.6857
  tradition:
    mae: 0.1502
    accuracy: 0.8619
    qwk: 0.4563
    spearman: 0.4854
    calibration: 0.8628
    hedging: 0.8667
  benevolence:
    mae: 0.2671
    accuracy: 0.7762
    qwk: 0.4332
    spearman: 0.4681
    calibration: 0.7964
    hedging: 0.6667
  universalism:
    mae: 0.2006
    accuracy: 0.8238
    qwk: 0.4661
    spearman: 0.5385
    calibration: 0.9205
    hedging: 0.819
observations: CORN at hd=64 achieves the best QWK of any nomic run (0.413, moderate) â€”
  a major recovery from CORN's poor showing at hd=32 (0.280 in run_006). Conformity
  breakthrough at QWK 0.535, tradition 0.456, universalism 0.466. Calibration 0.838
  (good). Training gap minimal (0.007). Power QWK 0.378 is the highest CORN has achieved
  on any nomic run. Security remains the weakest dimension (0.109). No more NaN QWK
  on hedonism (0.465), confirming the degenerate-prediction issue is resolved at higher
  capacity.
