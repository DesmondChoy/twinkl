# VIF Experiment: run_005_SoftOrdinal
# Generated: 2026-02-20T09:25:59
# Git: 4c48773(dirty)
metadata:
  experiment_id: run_005_SoftOrdinal
  run_id: run_005
  model_name: SoftOrdinal
  timestamp: '2026-02-20T09:25:59'
  git_commit: 4c48773(dirty)
  config_hash: 913a8cfd6a52
provenance:
  prev_run_id: run_003
  prev_git_commit: a3f493f
  git_log:
  - '4c48773 docs: remove redundant introductory sentences from AGENTS.md and GEMINI.md'
  - '31918e6 fix(vif): include dataset splits in experiment logger deduplication hash'
  - 'e5cb197 fix(vif): include dataset splits in experiment logger deduplication hash'
  - 'b84d1ca fix(judge): backfill rationales for 61 personas and fix under-labeled
    entry'
  - 'c0435e1 chore(data): add batch 2 judge labels for 60 new personas'
  - 'cd59d19 chore(data): add batch 2 synthetic and wrangled persona data (60 personas)'
  - '986e408 feat(judge): add consolidation module, harden wrangling parser, and update
    judge pipeline docs'
  - 'a036004 chore(data): remove batch 1A pre-tension Universalism personas (10)'
  - de4a5e1 Refactor notebook references to scripts and harden synthetic helpers (twinkl-ayp)
  - '62cbe11 docs(gen): fix config variables — remove dead START_DATE, wire MIN_DAYS_BETWEEN_ENTRIES'
  - '9e3e22a feat(vif): add runs 003/004 experiment logs with provenance backfill'
  config_delta:
    added:
      data.train_ratio: 0.7
      data.val_ratio: 0.15
      data.split_seed: 2025
      data.pct_truncated: 31.441
      data.state_dim: 1164
      uncertainty.mc_dropout_samples: 50
    removed: {}
    changed: {}
  rationale: Re-run of MiniLM-384d configuration with expanded dataset (958 train
    vs 637). Added 60 new personas from batch 2, removed 10 pre-tension Universalism
    personas, and added MC dropout uncertainty (50 samples). Tests whether 50% more
    data improves MiniLM performance.
config:
  encoder:
    model_name: all-MiniLM-L6-v2
  state_encoder:
    window_size: 3
  data:
    train_ratio: 0.7
    val_ratio: 0.15
    split_seed: 2025
    pct_truncated: 31.441
    state_dim: 1164
  model:
    hidden_dim: 256
    dropout: 0.2
  training:
    loss_fn: soft_ordinal
    learning_rate: 0.001
    weight_decay: 0.01
    batch_size: 16
    epochs: 100
    early_stopping_patience: 20
    scheduler_factor: 0.5
    scheduler_patience: 10
    seed: 2025
  uncertainty:
    mc_dropout_samples: 50
data:
  n_train: 958
  n_val: 214
  n_test: 202
capacity:
  n_parameters: 372766
  param_sample_ratio: 389.1086
training_dynamics:
  best_epoch: 1
  total_epochs: 21
  train_loss_at_best: 2.6798
  val_loss_at_best: 2.4296
  gap_at_best: -0.2502
  final_lr: 0.0005
evaluation:
  mae_mean: 0.2148
  accuracy_mean: 0.798
  qwk_mean: 0.304
  spearman_mean: 0.3676
  calibration_global: 0.6503
  calibration_positive_dims: 10
  mean_uncertainty: 0.078
  minority_recall_mean: 0.165
  recall_minus1: 0.0391
  recall_plus1: 0.2908
  hedging_mean: 0.896
per_dimension:
  self_direction:
    mae: 0.3369
    accuracy: 0.6733
    qwk: 0.1259
    spearman: 0.2079
    calibration: 0.5333
    hedging: 0.9059
  stimulation:
    mae: 0.13
    accuracy: 0.8762
    qwk: 0.4102
    spearman: 0.5256
    calibration: 0.7467
    hedging: 0.9307
  hedonism:
    mae: 0.1074
    accuracy: 0.901
    qwk: 0.5875
    spearman: 0.5502
    calibration: 0.7729
    hedging: 0.9059
  achievement:
    mae: 0.2684
    accuracy: 0.7475
    qwk: 0.3977
    spearman: 0.5127
    calibration: 0.6409
    hedging: 0.7475
  power:
    mae: 0.1506
    accuracy: 0.8515
    qwk: 0.0605
    spearman: 0.238
    calibration: 0.3391
    hedging: 0.995
  security:
    mae: 0.2169
    accuracy: 0.8168
    qwk: 0.4457
    spearman: 0.4104
    calibration: 0.7051
    hedging: 0.8614
  conformity:
    mae: 0.2546
    accuracy: 0.7475
    qwk: .nan
    spearman: 0.1113
    calibration: 0.4688
    hedging: 0.995
  tradition:
    mae: 0.1906
    accuracy: 0.8168
    qwk: 0.1608
    spearman: 0.3019
    calibration: 0.5973
    hedging: 0.9703
  benevolence:
    mae: 0.331
    accuracy: 0.6832
    qwk: 0.1908
    spearman: 0.2551
    calibration: 0.5208
    hedging: 0.802
  universalism:
    mae: 0.162
    accuracy: 0.8663
    qwk: 0.3567
    spearman: 0.5626
    calibration: 0.8174
    hedging: 0.8465
observations: SoftOrdinal QWK regressed from 0.383 (run_003) to 0.304 with the
  expanded dataset. Hedging is the worst of any run at 89.6%, with minority recall
  collapsing to 16.5%. Conformity QWK is NaN (99.5% hedging). Best_epoch=1 with
  negative training gap (-0.250) suggests the model barely learned before early
  stopping triggered — the larger dataset with MiniLM's massive param/sample ratio
  (389) creates a pathological training dynamic. Security was a bright spot (QWK
  0.446, best across SoftOrdinal runs). Hedonism remained strong (0.588).
