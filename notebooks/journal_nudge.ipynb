{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Journal Generation with Nudging\n",
    "\n",
    "This notebook extends the synthetic journal generation with a two-way conversational nudging system.\n",
    "When an entry is vague or potentially rich with unexplored tension, the system responds with a brief nudge that invites elaboration.\n",
    "\n",
    "**Design goal**: Nudges should feel like natural curiosity from a thoughtful companion, not interrogation or therapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import yaml\n",
    "import polars as pl\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from jinja2 import Template\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API Key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"WARNING: OPENAI_API_KEY not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs loaded successfully.\n",
      "Available Persona Attributes: ['age_ranges', 'cultures', 'professions', 'schwartz_values']\n",
      "Schwartz Values with elaborations: ['Self-Direction', 'Stimulation', 'Hedonism', 'Achievement', 'Power', 'Security', 'Conformity', 'Tradition', 'Benevolence', 'Universalism']\n",
      "Nudge config loaded: ['base_probability', 'response_probability', 'category_weights', 'response_modes', 'banned_phrases', 'min_words', 'max_words']\n"
     ]
    }
   ],
   "source": [
    "# Configuration Loading\n",
    "CONFIG_PATH = Path(\"config/synthetic_data.yaml\")\n",
    "if not CONFIG_PATH.exists():\n",
    "    CONFIG_PATH = Path(\"../config/synthetic_data.yaml\")\n",
    "\n",
    "SCHWARTZ_VALUES_PATH = Path(\"config/schwartz_values.yaml\")\n",
    "if not SCHWARTZ_VALUES_PATH.exists():\n",
    "    SCHWARTZ_VALUES_PATH = Path(\"../config/schwartz_values.yaml\")\n",
    "\n",
    "\n",
    "def load_config(path: str | Path) -> dict:\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "schwartz_config = load_config(SCHWARTZ_VALUES_PATH)\n",
    "\n",
    "print(\"Configs loaded successfully.\")\n",
    "print(f\"Available Persona Attributes: {list(config['personas'].keys())}\")\n",
    "print(f\"Schwartz Values with elaborations: {list(schwartz_config['values'].keys())}\")\n",
    "print(f\"Nudge config loaded: {list(config['nudge'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "Extended models for conversational journaling with nudges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models (from journal_gen.ipynb)\n",
    "class Persona(BaseModel):\n",
    "    name: str = Field(description=\"Full name of the persona\")\n",
    "    age: str\n",
    "    profession: str\n",
    "    culture: str\n",
    "    core_values: list[str] = Field(description=\"Top 3 Schwartz values\")\n",
    "    bio: str = Field(\n",
    "        description=\"A short paragraph describing their background, stressors, and goals\"\n",
    "    )\n",
    "\n",
    "\n",
    "class JournalEntry(BaseModel):\n",
    "    \"\"\"LLM-generated journal entry. Metadata (tone, verbosity, etc.) tracked separately.\"\"\"\n",
    "\n",
    "    date: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "# New models for conversational pipeline\n",
    "NudgeCategory = Literal[\n",
    "    \"clarification\", \"elaboration\", \"tension_surfacing\", \"grounding\"\n",
    "]\n",
    "\n",
    "\n",
    "class NudgeResult(BaseModel):\n",
    "    \"\"\"Generated nudge with metadata.\"\"\"\n",
    "\n",
    "    nudge_text: str\n",
    "    nudge_category: NudgeCategory\n",
    "    trigger_reason: str  # Why this nudge was generated\n",
    "    was_responded_to: bool = False\n",
    "\n",
    "\n",
    "class JournalTurn(BaseModel):\n",
    "    \"\"\"A single turn in the conversation (entry or response).\"\"\"\n",
    "\n",
    "    date: str\n",
    "    content: str\n",
    "    turn_type: Literal[\"initial_entry\", \"nudge_response\"]\n",
    "    responding_to_nudge: str | None = None  # The nudge text if this is a response\n",
    "\n",
    "\n",
    "class ConversationalEntry(BaseModel):\n",
    "    \"\"\"Complete conversational exchange for one journaling session.\"\"\"\n",
    "\n",
    "    initial_entry: JournalEntry\n",
    "    nudge: NudgeResult | None = None\n",
    "    response: JournalTurn | None = None  # User's response to the nudge\n",
    "    # Metadata\n",
    "    tone: str\n",
    "    verbosity: str\n",
    "    reflection_mode: str\n",
    "\n",
    "\n",
    "# JSON schemas for OpenAI structured output\n",
    "PERSONA_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"string\"},\n",
    "        \"profession\": {\"type\": \"string\"},\n",
    "        \"culture\": {\"type\": \"string\"},\n",
    "        \"core_values\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"bio\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\", \"profession\", \"culture\", \"core_values\", \"bio\"],\n",
    "}\n",
    "\n",
    "JOURNAL_ENTRY_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"date\": {\"type\": \"string\"},\n",
    "        \"content\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"date\", \"content\"],\n",
    "}\n",
    "\n",
    "NUDGE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"nudge_text\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"nudge_text\"],\n",
    "}\n",
    "\n",
    "NUDGE_RESPONSE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"content\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"content\"],\n",
    "}\n",
    "\n",
    "PERSONA_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"Persona\",\n",
    "    \"schema\": PERSONA_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "JOURNAL_ENTRY_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"JournalEntry\",\n",
    "    \"schema\": JOURNAL_ENTRY_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "NUDGE_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"Nudge\",\n",
    "    \"schema\": NUDGE_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "NUDGE_RESPONSE_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"NudgeResponse\",\n",
    "    \"schema\": NUDGE_RESPONSE_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_value_context(values: list[str], schwartz_config: dict) -> str:\n",
    "    \"\"\"Build rich context about Schwartz values for persona generation.\n",
    "\n",
    "    Args:\n",
    "        values: List of Schwartz value names (e.g., [\"Achievement\", \"Benevolence\"])\n",
    "        schwartz_config: The loaded schwartz_values.yaml config\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with value elaborations for prompt injection\n",
    "    \"\"\"\n",
    "    context_parts = []\n",
    "\n",
    "    for value_name in values:\n",
    "        if value_name not in schwartz_config[\"values\"]:\n",
    "            continue\n",
    "\n",
    "        v = schwartz_config[\"values\"][value_name]\n",
    "\n",
    "        # Build a focused context block for this value\n",
    "        context_parts.append(f\"\"\"\n",
    "### {value_name}\n",
    "**Core Motivation:** {v[\"core_motivation\"].strip()}\n",
    "\n",
    "**How this manifests in behavior:**\n",
    "{chr(10).join(f\"- {b}\" for b in v[\"behavioral_manifestations\"][:5])}\n",
    "\n",
    "**Life domain expressions:**\n",
    "- Work: {v[\"life_domain_expressions\"][\"work\"].strip()}\n",
    "- Relationships: {v[\"life_domain_expressions\"][\"relationships\"].strip()}\n",
    "\n",
    "**Typical stressors for this person:**\n",
    "{chr(10).join(f\"- {s}\" for s in v[\"typical_stressors\"][:4])}\n",
    "\n",
    "**Typical goals:**\n",
    "{chr(10).join(f\"- {g}\" for g in v[\"typical_goals\"][:3])}\n",
    "\n",
    "**Internal conflicts they may experience:**\n",
    "{v[\"internal_conflicts\"].strip()}\n",
    "\n",
    "**Narrative guidance:**\n",
    "{v[\"persona_narrative_guidance\"].strip()}\n",
    "\"\"\")\n",
    "\n",
    "    return \"\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_generation_prompt = Template(\"\"\"\n",
    "You are generating synthetic personas for a journaling dataset.\n",
    "\n",
    "## Constraints\n",
    "- Age Group: {{ age }}\n",
    "- Profession: {{ profession }}\n",
    "- Cultural Background: {{ culture }}\n",
    "- Schwartz values to embody: {{ values | join(', ') }}\n",
    "\n",
    "## Value Psychology Reference\n",
    "Use the following research-based elaborations to understand how the assigned value(s) shape a person's life circumstances, stressors, and motivations. DO NOT mention any of these concepts explicitly in your output—use them only to inform realistic details.\n",
    "\n",
    "{{ value_context }}\n",
    "\n",
    "## Your Task\n",
    "Create a persona whose life circumstances, stressors, and motivations naturally reflect the given Schwartz values—without ever naming or describing those values explicitly.\n",
    "\n",
    "## Rules\n",
    "- Return ONLY valid JSON matching the Persona schema.\n",
    "- `core_values` must be exactly: {{ values | join(', ') }} (same spelling/case).\n",
    "- `bio` must be 2–4 sentences describing their background, current life situation, stressors, and what drives them.\n",
    "- `bio` must be written in third-person (use their name or \"they\"; do not use \"I\").\n",
    "- `bio` must show the values through CONCRETE DETAILS (job choices, relationships, conflicts, goals, specific situations) NOT through labels, personality descriptions, or adjectives.\n",
    "- `bio` must NOT contain any Schwartz value labels, the word \"Schwartz\", or derivative adjectives.\n",
    "- `bio` must NOT describe journaling app features (avoid words like \"templates\", \"analytics\", \"private app\").\n",
    "- Use the behavioral manifestations, life domain expressions, and typical stressors from the Value Psychology Reference to craft realistic, specific details.\n",
    "\n",
    "## Banned terms (do not use in bio)\n",
    "{{ banned_terms | join(', ') }}\n",
    "\n",
    "## Examples of what NOT to write\n",
    "- \"She is achievement-oriented and seeks power\" ❌ (uses value labels)\n",
    "- \"He values security and tradition\" ❌ (explicitly mentions values)\n",
    "- \"They are a hedonistic person who enjoys pleasure\" ❌ (uses derivative adjectives)\n",
    "- \"She is driven and ambitious\" ❌ (personality adjectives instead of concrete details)\n",
    "\n",
    "## Examples of what TO write\n",
    "- \"She recently turned down a stable government job to launch her own startup, and now juggles investor meetings while her savings dwindle.\" ✓ (shows Achievement through concrete career choice and trade-offs)\n",
    "- \"He moved back to his hometown after his father's illness, taking over the family shop despite having built a career in the city.\" ✓ (shows Tradition/Benevolence through specific life situation)\n",
    "- \"She keeps a spreadsheet tracking her publication submissions and citation counts, and measures her weeks by how many grant deadlines she meets.\" ✓ (shows Achievement through specific behaviors)\n",
    "\n",
    "## Output\n",
    "Return valid JSON matching the Persona schema:\n",
    "{ \n",
    "  \"name\": \"...\", \n",
    "  \"age\": \"...\", \n",
    "  \"profession\": \"...\", \n",
    "  \"culture\": \"...\", \n",
    "  \"core_values\": [\"...\"], \n",
    "  \"bio\": \"...\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "journal_entry_prompt = Template(\"\"\"\n",
    "You are {{ name }}, a {{ age }} {{ profession }} from {{ culture }}.\n",
    "Background (for context only): {{ bio }}\n",
    "\n",
    "Write a typed journal entry in English for {{ date }}.\n",
    "{% if previous_entries %}\n",
    "Previous journal entries (for continuity—you may reference past events/thoughts, but do not repeat them):\n",
    "{% for prev in previous_entries %}\n",
    "---\n",
    "{{ prev.date }}: {{ prev.content }}\n",
    "{% endfor %}\n",
    "---\n",
    "{% endif %}\n",
    "\n",
    "Context:\n",
    "- Tone: {{ tone }}\n",
    "- Verbosity: {{ verbosity }} (target {{ min_words }}–{{ max_words }} words)\n",
    "\n",
    "Cultural context:\n",
    "- Your {{ culture }} background should subtly flavor your perspective and the details you mention.\n",
    "- It should feel natural and \"lived-in,\" avoiding stereotypes or travel-guide descriptions.\n",
    "\n",
    "What to write about:\n",
    "{% if reflection_mode == 'Unsettled' %}\n",
    "Something happened where you made a choice that felt necessary or easier in the moment—but it sits a bit wrong. Maybe you gave ground on something, went along with pressure, or took a shortcut you wouldn't usually take. Don't analyze it or name why it bothers you. Just describe what happened and let the discomfort sit there.\n",
    "{% elif reflection_mode == 'Grounded' %}\n",
    "Something happened where you acted like yourself—the version of you that you want to be. It wasn't a big moment, just a small one where things felt right. Don't celebrate it or moralize. Just describe the moment.\n",
    "{% else %}\n",
    "Nothing particular happened. Write about a routine day—small details, passing thoughts, mundane observations. No revelations or turning points.\n",
    "{% endif %}\n",
    "\n",
    "Style rules (important):\n",
    "- Write like a real personal journal: plain, candid, sometimes messy or fragmented.\n",
    "- Do not write for an audience. No \"Dear Diary\" or performing for a reader.\n",
    "- Do not open with the time of day, weather, or \"Today I...\" summaries.\n",
    "- Jump into a thought, moment, or feeling mid-stream.\n",
    "- Avoid \"therapy speak\" (e.g., \"I am processing my emotions\", \"I recognize this pattern\").\n",
    "- Avoid literary metaphors, edgy humor/snark, and audience-facing jokes.\n",
    "- No headings, no numbered plans, no bullet lists.\n",
    "- Keep to {{ max_paragraphs }} short paragraph(s).\n",
    "\n",
    "Avoid openings like:\n",
    "- \"Morning light feels stubborn as I...\" ❌\n",
    "- \"Evening. Today followed the usual rhythm...\" ❌\n",
    "- \"Lunch break finally settles in...\" ❌\n",
    "\n",
    "Output valid JSON:\n",
    "{\n",
    "  \"date\": \"{{ date }}\",\n",
    "  \"content\": \"...\"\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "nudge_generation_prompt = Template(\"\"\"\n",
    "You are generating a brief follow-up for a journaling app.\n",
    "\n",
    "## Context\n",
    "User's entry: {{ entry_content }}\n",
    "Entry date: {{ entry_date }}\n",
    "Nudge category: {{ nudge_category }}\n",
    "{% if previous_entries %}\n",
    "Recent entries (for context):\n",
    "{% for prev in previous_entries %}\n",
    "- {{ prev.date }}: {{ prev.content[:150] }}{% if prev.content|length > 150 %}...{% endif %}\n",
    "{% endfor %}\n",
    "{% endif %}\n",
    "\n",
    "## Your Task\n",
    "Generate a SHORT follow-up question ({{ min_words }}-{{ max_words }} words) that:\n",
    "- Matches the category: {{ nudge_category }}\n",
    "- Sounds like natural curiosity, not therapy\n",
    "- References something specific from the entry\n",
    "- Uses simple, casual language\n",
    "\n",
    "## Examples by Category\n",
    "{% if nudge_category == 'clarification' %}\n",
    "- \"What happened right before that?\"\n",
    "- \"The meeting?\"\n",
    "- \"Since when?\"\n",
    "{% elif nudge_category == 'elaboration' %}\n",
    "- \"And how did that land?\"\n",
    "- \"What did you end up doing?\"\n",
    "- \"What got you over the line?\"\n",
    "{% elif nudge_category == 'tension_surfacing' %}\n",
    "- \"What's the 'sort of' part?\"\n",
    "- \"Does that sit okay?\"\n",
    "- \"What stopped you?\"\n",
    "{% elif nudge_category == 'grounding' %}\n",
    "- \"What made it good?\"\n",
    "- \"What worked?\"\n",
    "- \"What made it nice?\"\n",
    "{% endif %}\n",
    "\n",
    "## Banned Phrases\n",
    "{% for phrase in banned_phrases %}\n",
    "- \"{{ phrase }}\"\n",
    "{% endfor %}\n",
    "- Any phrase over {{ max_words }} words\n",
    "\n",
    "## Output\n",
    "Return ONLY valid JSON:\n",
    "{\"nudge_text\": \"your question here\"}\n",
    "\"\"\")\n",
    "\n",
    "nudge_response_prompt = Template(\"\"\"\n",
    "You are {{ name }}, a {{ age }} {{ profession }} from {{ culture }}.\n",
    "Background: {{ bio }}\n",
    "\n",
    "You just wrote this journal entry:\n",
    "---\n",
    "{{ entry_content }}\n",
    "---\n",
    "\n",
    "The journaling app asked you: \"{{ nudge_text }}\"\n",
    "\n",
    "## Your Task\n",
    "Write a brief response ({{ min_words }}-{{ max_words }} words) in the style of: {{ response_mode }}\n",
    "\n",
    "## Response Mode Guidance\n",
    "{% if response_mode == 'Answering directly' %}\n",
    "Give a clear, helpful response to the question. Don't dodge it.\n",
    "{% elif response_mode == 'Deflecting/redirecting' %}\n",
    "Give a brief acknowledgment or change the topic slightly. \"Yeah, just the usual\" or \"I don't know, maybe.\"\n",
    "{% elif response_mode == 'Revealing deeper thought' %}\n",
    "The question prompts you to be more honest than you were in the original entry. Say something you held back.\n",
    "{% endif %}\n",
    "\n",
    "## Style Rules\n",
    "- Write as if you're quickly typing a response in the app\n",
    "- Match the tone of your original entry\n",
    "- Don't repeat what you already wrote\n",
    "- No \"therapy speak\" or formal language\n",
    "- Can be incomplete sentences or fragments\n",
    "\n",
    "## Output\n",
    "Return ONLY valid JSON:\n",
    "{\"content\": \"your response here\"}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Client Setup\n",
    "\n",
    "Using `gpt-5-mini`. \n",
    "\n",
    "**Note:** GPT-5 models do not support `temperature` or `top_p` parameters. Instead, use the `reasoning` parameter to control how much the model \"thinks\" before responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()\n",
    "MODEL_NAME = \"gpt-5-mini-2025-08-07\"\n",
    "# MODEL_NAME = \"gpt-5-nano-2025-08-07\"\n",
    "\n",
    "# Type alias for reasoning effort levels\n",
    "ReasoningEffort = Literal[\"minimal\", \"low\", \"medium\", \"high\"]\n",
    "\n",
    "# Default reasoning effort - change this to affect all generations\n",
    "DEFAULT_REASONING_EFFORT: ReasoningEffort = \"high\"\n",
    "\n",
    "\n",
    "async def generate_completion(\n",
    "    prompt: str,\n",
    "    response_format: dict | None = None,\n",
    ") -> str | None:\n",
    "    \"\"\"Generate a completion using the OpenAI Responses API (async).\n",
    "\n",
    "    Uses DEFAULT_REASONING_EFFORT to control how much the model \"thinks\".\n",
    "    Valid reasoning effort values: \"minimal\", \"low\", \"medium\", \"high\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        kwargs = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"input\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"reasoning\": {\"effort\": DEFAULT_REASONING_EFFORT},\n",
    "        }\n",
    "\n",
    "        if response_format:\n",
    "            kwargs[\"text\"] = {\"format\": response_format}\n",
    "\n",
    "        response = await client.responses.create(**kwargs)\n",
    "        return response.output_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completion: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _verbosity_targets(verbosity: str) -> tuple[int, int, int]:\n",
    "    \"\"\"Returns (min_words, max_words, max_paragraphs) as guidance for the LLM.\"\"\"\n",
    "    normalized = verbosity.strip().lower()\n",
    "    if normalized.startswith(\"short\"):\n",
    "        return 25, 80, 1\n",
    "    if normalized.startswith(\"medium\"):\n",
    "        return 90, 180, 2\n",
    "    return 160, 260, 3\n",
    "\n",
    "\n",
    "def _build_banned_pattern(banned_terms: list[str]) -> re.Pattern:\n",
    "    \"\"\"Build regex pattern to detect banned Schwartz value terms.\"\"\"\n",
    "    escaped = [re.escape(term) for term in banned_terms if term.strip()]\n",
    "    if not escaped:\n",
    "        return re.compile(r\"$^\")\n",
    "    return re.compile(r\"(?i)\\b(\" + \"|\".join(escaped) + r\")\\b\")\n",
    "\n",
    "\n",
    "def generate_date_sequence(\n",
    "    start_date: str, num_entries: int, min_days: int = 2, max_days: int = 10\n",
    ") -> list[str]:\n",
    "    \"\"\"Generate a sequence of dates with random intervals.\n",
    "\n",
    "    Args:\n",
    "        start_date: Starting date in YYYY-MM-DD format\n",
    "        num_entries: Number of dates to generate\n",
    "        min_days: Minimum days between entries\n",
    "        max_days: Maximum days between entries\n",
    "\n",
    "    Returns:\n",
    "        List of date strings in YYYY-MM-DD format\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    current = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "    for i in range(num_entries):\n",
    "        dates.append(current.strftime(\"%Y-%m-%d\"))\n",
    "        if i < num_entries - 1:\n",
    "            days_gap = random.randint(min_days, max_days)\n",
    "            current += timedelta(days=days_gap)\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "# Banned terms include Schwartz value labels AND derivative adjectives\n",
    "SCHWARTZ_BANNED_TERMS = [\n",
    "    # Value labels\n",
    "    \"Self-Direction\",\n",
    "    \"Stimulation\",\n",
    "    \"Hedonism\",\n",
    "    \"Achievement\",\n",
    "    \"Power\",\n",
    "    \"Security\",\n",
    "    \"Conformity\",\n",
    "    \"Tradition\",\n",
    "    \"Benevolence\",\n",
    "    \"Universalism\",\n",
    "    # Derivative adjectives and related terms\n",
    "    \"self-directed\",\n",
    "    \"autonomous\",\n",
    "    \"stimulating\",\n",
    "    \"excited\",\n",
    "    \"hedonistic\",\n",
    "    \"hedonist\",\n",
    "    \"pleasure-seeking\",\n",
    "    \"achievement-oriented\",\n",
    "    \"ambitious\",\n",
    "    \"powerful\",\n",
    "    \"authoritative\",\n",
    "    \"secure\",\n",
    "    \"conformist\",\n",
    "    \"conforming\",\n",
    "    \"traditional\",\n",
    "    \"traditionalist\",\n",
    "    \"benevolent\",\n",
    "    \"kind-hearted\",\n",
    "    \"universalistic\",\n",
    "    \"altruistic\",\n",
    "    # Meta terms\n",
    "    \"Schwartz\",\n",
    "    \"values\",\n",
    "    \"core values\",\n",
    "]\n",
    "\n",
    "BANNED_PATTERN = _build_banned_pattern(SCHWARTZ_BANNED_TERMS)\n",
    "\n",
    "\n",
    "def _build_nudge_banned_pattern(banned_phrases: list[str]) -> re.Pattern:\n",
    "    \"\"\"Build regex pattern to detect banned nudge phrases.\"\"\"\n",
    "    escaped = [re.escape(phrase) for phrase in banned_phrases if phrase.strip()]\n",
    "    if not escaped:\n",
    "        return re.compile(r\"$^\")\n",
    "    return re.compile(r\"(?i)(\" + \"|\".join(escaped) + r\")\")\n",
    "\n",
    "\n",
    "NUDGE_BANNED_PATTERN = _build_nudge_banned_pattern(config[\"nudge\"][\"banned_phrases\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nudge Decision Logic\n",
    "\n",
    "Rule-based logic to decide whether to nudge and which category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test vague entry: should_nudge=True, category=clarification, reason=Entry too vague (low word count, no concrete details)\n",
      "Test hedging entry: should_nudge=True, category=tension_surfacing, reason=Hedging language detected in unsettled entry\n"
     ]
    }
   ],
   "source": [
    "# Hedging language patterns for tension detection\n",
    "HEDGING_PATTERNS = re.compile(\n",
    "    r\"(?i)\\b(sort of|kind of|i guess|maybe|i suppose|not sure|I don't know|whatever|fine|okay|it's fine|it was fine)\\b\"\n",
    ")\n",
    "\n",
    "# Concrete noun/verb patterns (simple heuristic)\n",
    "CONCRETE_PATTERNS = re.compile(\n",
    "    r\"(?i)\\b(meeting|call|email|project|deadline|boss|colleague|friend|family|mom|dad|sister|brother|work|office|home|school|doctor|money|car|phone|computer)\\b\"\n",
    ")\n",
    "\n",
    "\n",
    "def count_words(text: str) -> int:\n",
    "    \"\"\"Count words in text.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def has_hedging_language(text: str) -> bool:\n",
    "    \"\"\"Check if text contains hedging language suggesting tension.\"\"\"\n",
    "    return bool(HEDGING_PATTERNS.search(text))\n",
    "\n",
    "\n",
    "def has_concrete_details(text: str) -> bool:\n",
    "    \"\"\"Check if text has concrete nouns/verbs (simple heuristic).\"\"\"\n",
    "    return bool(CONCRETE_PATTERNS.search(text))\n",
    "\n",
    "\n",
    "def is_too_vague(entry: JournalEntry) -> bool:\n",
    "    \"\"\"Check if entry is too vague to score meaningfully.\"\"\"\n",
    "    word_count = count_words(entry.content)\n",
    "    return word_count < 15 and not has_concrete_details(entry.content)\n",
    "\n",
    "\n",
    "def is_neutral_routine(entry: JournalEntry, reflection_mode: str) -> bool:\n",
    "    \"\"\"Check if entry is a neutral/routine entry that shouldn't be nudged.\"\"\"\n",
    "    # Respect neutral entries - don't force depth where there isn't any\n",
    "    if reflection_mode == \"Neutral\":\n",
    "        word_count = count_words(entry.content)\n",
    "        # Short neutral entries without hedging are truly routine\n",
    "        if word_count < 80 and not has_hedging_language(entry.content):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def is_grounded_but_brief(entry: JournalEntry, reflection_mode: str) -> bool:\n",
    "    \"\"\"Check if entry is grounded/positive but brief.\"\"\"\n",
    "    return reflection_mode == \"Grounded\" and count_words(entry.content) < 50\n",
    "\n",
    "\n",
    "def weighted_choice(weights: dict[str, float]) -> str:\n",
    "    \"\"\"Make a weighted random choice from a dict of {option: weight}.\"\"\"\n",
    "    options = list(weights.keys())\n",
    "    probs = list(weights.values())\n",
    "    total = sum(probs)\n",
    "    probs = [p / total for p in probs]  # Normalize\n",
    "    return random.choices(options, weights=probs, k=1)[0]\n",
    "\n",
    "\n",
    "def decide_nudge(\n",
    "    entry: JournalEntry,\n",
    "    reflection_mode: str,\n",
    "    previous_entries: list[\"ConversationalEntry\"] | None,\n",
    "    config: dict,\n",
    ") -> tuple[bool, NudgeCategory | None, str | None]:\n",
    "    \"\"\"Decide whether to nudge and which category.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (should_nudge, nudge_category, trigger_reason)\n",
    "    \"\"\"\n",
    "    nudge_config = config[\"nudge\"]\n",
    "\n",
    "    # Anti-annoyance: session cap (2 nudges in last 3 entries)\n",
    "    if previous_entries:\n",
    "        recent_nudge_count = sum(\n",
    "            1 for e in previous_entries[-3:] if e.nudge is not None\n",
    "        )\n",
    "        if recent_nudge_count >= 2:\n",
    "            return False, None, None\n",
    "\n",
    "    # Decision tree\n",
    "\n",
    "    # 1. Too vague to score?\n",
    "    if is_too_vague(entry):\n",
    "        return (\n",
    "            True,\n",
    "            \"clarification\",\n",
    "            \"Entry too vague (low word count, no concrete details)\",\n",
    "        )\n",
    "\n",
    "    # 2. Neutral/routine entry?\n",
    "    if is_neutral_routine(entry, reflection_mode):\n",
    "        return False, None, None  # Respect the mundane\n",
    "\n",
    "    # 3. Potential tension detected?\n",
    "    if has_hedging_language(entry.content) and reflection_mode == \"Unsettled\":\n",
    "        return True, \"tension_surfacing\", \"Hedging language detected in unsettled entry\"\n",
    "\n",
    "    # 4. Grounded but brief?\n",
    "    if is_grounded_but_brief(entry, reflection_mode):\n",
    "        return True, \"grounding\", \"Grounded entry but brief - invite specifics\"\n",
    "\n",
    "    # 5. Random gate for elaboration (base_probability from config)\n",
    "    base_prob = nudge_config[\"base_probability\"]\n",
    "    if random.random() < base_prob:\n",
    "        return True, \"elaboration\", \"Random elaboration gate passed\"\n",
    "\n",
    "    return False, None, None\n",
    "\n",
    "\n",
    "# Test the decision logic\n",
    "test_entry = JournalEntry(date=\"2024-01-15\", content=\"Feeling off today.\")\n",
    "should, category, reason = decide_nudge(test_entry, \"Unsettled\", None, config)\n",
    "print(f\"Test vague entry: should_nudge={should}, category={category}, reason={reason}\")\n",
    "\n",
    "test_entry2 = JournalEntry(\n",
    "    date=\"2024-01-15\",\n",
    "    content=\"Had a meeting with the team about the project deadline. It was fine, I guess. We sorted out the schedule.\",\n",
    ")\n",
    "should2, category2, reason2 = decide_nudge(test_entry2, \"Unsettled\", None, config)\n",
    "print(\n",
    "    f\"Test hedging entry: should_nudge={should2}, category={category2}, reason={reason2}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nudge Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_nudge(\n",
    "    entry: JournalEntry,\n",
    "    category: NudgeCategory,\n",
    "    previous_entries: list[ConversationalEntry] | None,\n",
    "    config: dict,\n",
    "    max_attempts: int = 2,\n",
    ") -> tuple[str | None, str]:\n",
    "    \"\"\"Generate a nudge for the given entry.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (nudge_text or None, prompt used)\n",
    "    \"\"\"\n",
    "    nudge_config = config[\"nudge\"]\n",
    "\n",
    "    # Format previous entries for context\n",
    "    prev_entries_data = None\n",
    "    if previous_entries:\n",
    "        prev_entries_data = [\n",
    "            {\"date\": e.initial_entry.date, \"content\": e.initial_entry.content}\n",
    "            for e in previous_entries[-3:]  # Last 3 entries for context\n",
    "        ]\n",
    "\n",
    "    prompt = nudge_generation_prompt.render(\n",
    "        entry_content=entry.content,\n",
    "        entry_date=entry.date,\n",
    "        nudge_category=category,\n",
    "        previous_entries=prev_entries_data,\n",
    "        banned_phrases=nudge_config[\"banned_phrases\"],\n",
    "        min_words=nudge_config[\"min_words\"],\n",
    "        max_words=nudge_config[\"max_words\"],\n",
    "    )\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=NUDGE_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        data = json.loads(raw_json)\n",
    "        nudge_text = data.get(\"nudge_text\", \"\").strip()\n",
    "\n",
    "        # Validation\n",
    "        word_count = count_words(nudge_text)\n",
    "        if (\n",
    "            word_count < nudge_config[\"min_words\"]\n",
    "            or word_count > nudge_config[\"max_words\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        # Check banned phrases\n",
    "        if NUDGE_BANNED_PATTERN.search(nudge_text):\n",
    "            continue\n",
    "\n",
    "        return nudge_text, prompt\n",
    "\n",
    "    return None, prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nudge Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_response_mode(config: dict) -> str:\n",
    "    \"\"\"Select a response mode based on configured weights.\"\"\"\n",
    "    modes = config[\"nudge\"][\"response_modes\"]\n",
    "    weights = {m[\"mode\"]: m[\"weight\"] for m in modes}\n",
    "    return weighted_choice(weights)\n",
    "\n",
    "\n",
    "async def generate_nudge_response(\n",
    "    persona: Persona,\n",
    "    entry: JournalEntry,\n",
    "    nudge_text: str,\n",
    "    config: dict,\n",
    "    max_attempts: int = 2,\n",
    ") -> tuple[JournalTurn | None, str, str]:\n",
    "    \"\"\"Generate a response to a nudge.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (JournalTurn or None, prompt used, response_mode)\n",
    "    \"\"\"\n",
    "    response_mode = select_response_mode(config)\n",
    "\n",
    "    # Adjust word targets based on response mode\n",
    "    if response_mode == \"Deflecting/redirecting\":\n",
    "        min_words, max_words = 5, 30\n",
    "    elif response_mode == \"Revealing deeper thought\":\n",
    "        min_words, max_words = 20, 80\n",
    "    else:  # Answering directly\n",
    "        min_words, max_words = 15, 60\n",
    "\n",
    "    prompt = nudge_response_prompt.render(\n",
    "        name=persona.name,\n",
    "        age=persona.age,\n",
    "        profession=persona.profession,\n",
    "        culture=persona.culture,\n",
    "        bio=persona.bio,\n",
    "        entry_content=entry.content,\n",
    "        nudge_text=nudge_text,\n",
    "        response_mode=response_mode,\n",
    "        min_words=min_words,\n",
    "        max_words=max_words,\n",
    "    )\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=NUDGE_RESPONSE_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        data = json.loads(raw_json)\n",
    "        content = data.get(\"content\", \"\").strip()\n",
    "\n",
    "        if content:\n",
    "            turn = JournalTurn(\n",
    "                date=entry.date,\n",
    "                content=content,\n",
    "                turn_type=\"nudge_response\",\n",
    "                responding_to_nudge=nudge_text,\n",
    "            )\n",
    "            return turn, prompt, response_mode\n",
    "\n",
    "    return None, prompt, response_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConversationalPipelineResult:\n",
    "    \"\"\"Complete results from one persona's conversational generation pipeline.\"\"\"\n",
    "\n",
    "    persona_id: int\n",
    "    persona: Persona | None\n",
    "    entries: list[ConversationalEntry]\n",
    "    persona_prompt: str\n",
    "    entry_prompts: list[str]\n",
    "    nudge_prompts: list[str] = field(default_factory=list)\n",
    "    response_prompts: list[str] = field(default_factory=list)\n",
    "    error: str | None = None\n",
    "\n",
    "\n",
    "async def create_random_persona(\n",
    "    config: dict, schwartz_config: dict, max_attempts: int = 2\n",
    ") -> tuple[Persona | None, str]:\n",
    "    \"\"\"Generate a random persona with Schwartz values shown through life circumstances.\"\"\"\n",
    "    age = random.choice(config[\"personas\"][\"age_ranges\"])\n",
    "    prof = random.choice(config[\"personas\"][\"professions\"])\n",
    "    cult = random.choice(config[\"personas\"][\"cultures\"])\n",
    "    num_values = random.choice([1, 2])\n",
    "    vals = random.sample(config[\"personas\"][\"schwartz_values\"], num_values)\n",
    "\n",
    "    # Build rich value context from the Schwartz elaborations\n",
    "    value_context = build_value_context(vals, schwartz_config)\n",
    "\n",
    "    prompt = persona_generation_prompt.render(\n",
    "        age=age,\n",
    "        profession=prof,\n",
    "        culture=cult,\n",
    "        values=vals,\n",
    "        value_context=value_context,\n",
    "        banned_terms=SCHWARTZ_BANNED_TERMS,\n",
    "    )\n",
    "\n",
    "    first_person_pattern = re.compile(r\"(?i)\\b(i|my|me)\\b\")\n",
    "    last_persona: Persona | None = None\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=PERSONA_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        data = json.loads(raw_json)\n",
    "        data[\"core_values\"] = vals  # Ensure correct values\n",
    "        persona = Persona(**data)\n",
    "        last_persona = persona\n",
    "\n",
    "        # Only validate banned terms and first-person usage\n",
    "        if BANNED_PATTERN.search(persona.bio) or first_person_pattern.search(\n",
    "            persona.bio\n",
    "        ):\n",
    "            continue\n",
    "        return persona, prompt\n",
    "\n",
    "    return last_persona, prompt\n",
    "\n",
    "\n",
    "async def generate_journal_entry(\n",
    "    persona: Persona,\n",
    "    config: dict,\n",
    "    date_str: str,\n",
    "    previous_entries: list[JournalEntry] | None = None,\n",
    "    max_attempts: int = 2,\n",
    ") -> tuple[tuple[JournalEntry, str, str, str] | None, str]:\n",
    "    \"\"\"Generate a journal entry for a persona on a given date.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of ((entry, tone, verbosity, reflection_mode) or None, prompt used)\n",
    "    \"\"\"\n",
    "    tone = random.choice(config[\"journal_entries\"][\"tones\"])\n",
    "    verbosity = random.choice(config[\"journal_entries\"][\"verbosity\"])\n",
    "    reflection_mode = random.choice(config[\"journal_entries\"][\"reflection_mode\"])\n",
    "    min_words, max_words, max_paragraphs = _verbosity_targets(verbosity)\n",
    "\n",
    "    # Format previous entries for the prompt\n",
    "    prev_entries_data = None\n",
    "    if previous_entries:\n",
    "        prev_entries_data = [\n",
    "            {\"date\": e.date, \"content\": e.content} for e in previous_entries\n",
    "        ]\n",
    "\n",
    "    prompt = journal_entry_prompt.render(\n",
    "        name=persona.name,\n",
    "        age=persona.age,\n",
    "        profession=persona.profession,\n",
    "        culture=persona.culture,\n",
    "        bio=persona.bio,\n",
    "        date=date_str,\n",
    "        tone=tone,\n",
    "        verbosity=verbosity,\n",
    "        min_words=min_words,\n",
    "        max_words=max_words,\n",
    "        max_paragraphs=max_paragraphs,\n",
    "        reflection_mode=reflection_mode,\n",
    "        previous_entries=prev_entries_data,\n",
    "    )\n",
    "\n",
    "    last_entry: JournalEntry | None = None\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=JOURNAL_ENTRY_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        entry = JournalEntry(**json.loads(raw_json))\n",
    "        last_entry = entry\n",
    "\n",
    "        # Only validate banned terms (prevent label leakage)\n",
    "        if not BANNED_PATTERN.search(entry.content):\n",
    "            return (entry, tone, verbosity, reflection_mode), prompt\n",
    "\n",
    "    if last_entry:\n",
    "        return (last_entry, tone, verbosity, reflection_mode), prompt\n",
    "    return None, prompt\n",
    "\n",
    "\n",
    "async def generate_conversational_entry(\n",
    "    persona: Persona,\n",
    "    config: dict,\n",
    "    date_str: str,\n",
    "    previous_entries: list[ConversationalEntry] | None = None,\n",
    ") -> tuple[ConversationalEntry | None, str, str | None, str | None]:\n",
    "    \"\"\"Generate entry, decide on nudge, optionally generate response.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (ConversationalEntry or None, entry_prompt, nudge_prompt, response_prompt)\n",
    "    \"\"\"\n",
    "    # Step 1: Generate initial entry\n",
    "    prev_journal_entries = [e.initial_entry for e in (previous_entries or [])]\n",
    "    entry_result, entry_prompt = await generate_journal_entry(\n",
    "        persona, config, date_str, previous_entries=prev_journal_entries\n",
    "    )\n",
    "\n",
    "    if not entry_result:\n",
    "        return None, entry_prompt, None, None\n",
    "\n",
    "    entry, tone, verbosity, reflection_mode = entry_result\n",
    "\n",
    "    # Step 2: Decide whether to nudge\n",
    "    # Note: tone is NOT passed to decide_nudge - it's synthetic metadata unavailable in production\n",
    "    should_nudge, nudge_category, trigger_reason = decide_nudge(\n",
    "        entry=entry,\n",
    "        reflection_mode=reflection_mode,\n",
    "        previous_entries=previous_entries,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    nudge_result = None\n",
    "    response = None\n",
    "    nudge_prompt = None\n",
    "    response_prompt = None\n",
    "\n",
    "    if should_nudge and nudge_category:\n",
    "        # Step 3: Generate nudge\n",
    "        nudge_text, nudge_prompt = await generate_nudge(\n",
    "            entry=entry,\n",
    "            category=nudge_category,\n",
    "            previous_entries=previous_entries,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        if nudge_text:\n",
    "            nudge_result = NudgeResult(\n",
    "                nudge_text=nudge_text,\n",
    "                nudge_category=nudge_category,\n",
    "                trigger_reason=trigger_reason or \"\",\n",
    "            )\n",
    "\n",
    "            # Step 4: Decide if persona responds (probabilistic)\n",
    "            if random.random() < config[\"nudge\"][\"response_probability\"]:\n",
    "                (\n",
    "                    response,\n",
    "                    response_prompt,\n",
    "                    response_mode,\n",
    "                ) = await generate_nudge_response(\n",
    "                    persona=persona, entry=entry, nudge_text=nudge_text, config=config\n",
    "                )\n",
    "                if response:\n",
    "                    nudge_result.was_responded_to = True\n",
    "\n",
    "    return (\n",
    "        ConversationalEntry(\n",
    "            initial_entry=entry,\n",
    "            nudge=nudge_result,\n",
    "            response=response,\n",
    "            tone=tone,\n",
    "            verbosity=verbosity,\n",
    "            reflection_mode=reflection_mode,\n",
    "        ),\n",
    "        entry_prompt,\n",
    "        nudge_prompt,\n",
    "        response_prompt,\n",
    "    )\n",
    "\n",
    "\n",
    "async def generate_conversational_pipeline(\n",
    "    persona_id: int,\n",
    "    config: dict,\n",
    "    schwartz_config: dict,\n",
    "    num_entries: int = 3,\n",
    "    start_date: str = \"2023-10-27\",\n",
    ") -> ConversationalPipelineResult:\n",
    "    \"\"\"Generate one persona and all their conversational journal entries.\"\"\"\n",
    "    entry_prompts: list[str] = []\n",
    "    nudge_prompts: list[str] = []\n",
    "    response_prompts: list[str] = []\n",
    "    entries: list[ConversationalEntry] = []\n",
    "\n",
    "    # 1. Generate persona\n",
    "    persona, persona_prompt = await create_random_persona(config, schwartz_config)\n",
    "\n",
    "    if not persona:\n",
    "        return ConversationalPipelineResult(\n",
    "            persona_id=persona_id,\n",
    "            persona=None,\n",
    "            entries=[],\n",
    "            persona_prompt=persona_prompt,\n",
    "            entry_prompts=[],\n",
    "            error=\"Failed to generate persona\",\n",
    "        )\n",
    "\n",
    "    # 2. Generate conversational entries sequentially\n",
    "    dates = generate_date_sequence(start_date, num_entries)\n",
    "\n",
    "    for date_str in dates:\n",
    "        (\n",
    "            conv_entry,\n",
    "            entry_prompt,\n",
    "            nudge_prompt,\n",
    "            response_prompt,\n",
    "        ) = await generate_conversational_entry(\n",
    "            persona, config, date_str, previous_entries=entries\n",
    "        )\n",
    "        entry_prompts.append(entry_prompt)\n",
    "        if nudge_prompt:\n",
    "            nudge_prompts.append(nudge_prompt)\n",
    "        if response_prompt:\n",
    "            response_prompts.append(response_prompt)\n",
    "\n",
    "        if conv_entry:\n",
    "            entries.append(conv_entry)\n",
    "\n",
    "    return ConversationalPipelineResult(\n",
    "        persona_id=persona_id,\n",
    "        persona=persona,\n",
    "        entries=entries,\n",
    "        persona_prompt=persona_prompt,\n",
    "        entry_prompts=entry_prompts,\n",
    "        nudge_prompts=nudge_prompts,\n",
    "        response_prompts=response_prompts,\n",
    "        error=None,\n",
    "    )\n",
    "\n",
    "\n",
    "async def run_parallel_conversational_personas(\n",
    "    num_personas: int,\n",
    "    config: dict,\n",
    "    schwartz_config: dict,\n",
    "    num_entries: int = 3,\n",
    "    start_date: str = \"2023-10-27\",\n",
    ") -> list[ConversationalPipelineResult | Exception]:\n",
    "    \"\"\"Run multiple conversational persona pipelines in parallel.\"\"\"\n",
    "    tasks = [\n",
    "        generate_conversational_pipeline(\n",
    "            i + 1, config, schwartz_config, num_entries, start_date\n",
    "        )\n",
    "        for i in range(num_personas)\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Logging System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir() -> Path:\n",
    "    \"\"\"Create and return a timestamped log directory.\"\"\"\n",
    "    base_dir = Path(\"logs/synthetic_data\")\n",
    "    if not base_dir.exists():\n",
    "        base_dir = Path(\"../logs/synthetic_data\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_dir = base_dir / timestamp\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    return log_dir\n",
    "\n",
    "\n",
    "def write_config_log(\n",
    "    log_dir: Path, config: dict, num_personas: int, num_entries: int\n",
    ") -> None:\n",
    "    \"\"\"Write config.md with run parameters.\"\"\"\n",
    "    content = f\"\"\"# Run Configuration\n",
    "\n",
    "**Timestamp**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "**Notebook**: journal_nudge.ipynb\n",
    "\n",
    "## Persona Generation\n",
    "- Num personas: {num_personas}\n",
    "- Entries per persona: {num_entries}\n",
    "\n",
    "## Nudge Settings\n",
    "- Base probability: {config[\"nudge\"][\"base_probability\"]}\n",
    "- Response probability: {config[\"nudge\"][\"response_probability\"]}\n",
    "- Category weights: {config[\"nudge\"][\"category_weights\"]}\n",
    "\n",
    "## Model Settings\n",
    "- Model: {MODEL_NAME}\n",
    "- Reasoning effort: {DEFAULT_REASONING_EFFORT}\n",
    "\"\"\"\n",
    "    (log_dir / \"config.md\").write_text(content)\n",
    "\n",
    "\n",
    "def write_persona_log(log_dir: Path, result: ConversationalPipelineResult) -> None:\n",
    "    \"\"\"Write persona_XXX.md with all entries and nudges.\"\"\"\n",
    "    if not result.persona:\n",
    "        return\n",
    "\n",
    "    p = result.persona\n",
    "    lines = [\n",
    "        f\"# Persona {result.persona_id:03d}: {p.name}\",\n",
    "        \"\",\n",
    "        \"## Profile\",\n",
    "        f\"- Age: {p.age}\",\n",
    "        f\"- Profession: {p.profession}\",\n",
    "        f\"- Culture: {p.culture}\",\n",
    "        f\"- Core Values: {', '.join(p.core_values)}\",\n",
    "        f\"- Bio: {p.bio}\",\n",
    "        \"\",\n",
    "        \"---\",\n",
    "    ]\n",
    "\n",
    "    for i, entry in enumerate(result.entries, 1):\n",
    "        lines.extend(\n",
    "            [\n",
    "                \"\",\n",
    "                f\"## Entry {i} - {entry.initial_entry.date}\",\n",
    "                \"\",\n",
    "                \"### Initial Entry\",\n",
    "                f\"**Tone**: {entry.tone} | **Verbosity**: {entry.verbosity} | **Reflection Mode**: {entry.reflection_mode}\",\n",
    "                \"\",\n",
    "                entry.initial_entry.content,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if entry.nudge:\n",
    "            lines.extend(\n",
    "                [\n",
    "                    \"\",\n",
    "                    f\"### Nudge ({entry.nudge.nudge_category.replace('_', ' ').title()})\",\n",
    "                    f\"**Trigger**: {entry.nudge.trigger_reason}\",\n",
    "                    \"\",\n",
    "                    f'\"{entry.nudge.nudge_text}\"',\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if entry.response:\n",
    "                lines.extend(\n",
    "                    [\n",
    "                        \"\",\n",
    "                        \"### Response\",\n",
    "                        \"\",\n",
    "                        entry.response.content,\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                lines.append(\"\\n*(No response)*\")\n",
    "        else:\n",
    "            lines.append(\"\\n*(No nudge for this entry)*\")\n",
    "\n",
    "        lines.extend([\"\", \"---\"])\n",
    "\n",
    "    (log_dir / f\"persona_{result.persona_id:03d}.md\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "def write_prompts_log(\n",
    "    log_dir: Path, results: list[ConversationalPipelineResult]\n",
    ") -> None:\n",
    "    \"\"\"Write prompts.md with all LLM prompts.\"\"\"\n",
    "    lines = [\"# Prompts Log\", \"\"]\n",
    "\n",
    "    for result in results:\n",
    "        if isinstance(result, Exception) or not result.persona:\n",
    "            continue\n",
    "\n",
    "        lines.extend(\n",
    "            [\n",
    "                f\"## Persona {result.persona_id:03d}: {result.persona.name}\",\n",
    "                \"\",\n",
    "                \"### Persona Generation Prompt\",\n",
    "                \"```\",\n",
    "                result.persona_prompt,\n",
    "                \"```\",\n",
    "                \"\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i, prompt in enumerate(result.entry_prompts, 1):\n",
    "            lines.extend(\n",
    "                [\n",
    "                    f\"### Entry {i} - Initial Entry Prompt\",\n",
    "                    \"```\",\n",
    "                    prompt,\n",
    "                    \"```\",\n",
    "                    \"\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if result.nudge_prompts:\n",
    "            for i, prompt in enumerate(result.nudge_prompts, 1):\n",
    "                lines.extend(\n",
    "                    [\n",
    "                        f\"### Nudge Prompt {i}\",\n",
    "                        \"```\",\n",
    "                        prompt,\n",
    "                        \"```\",\n",
    "                        \"\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        if result.response_prompts:\n",
    "            for i, prompt in enumerate(result.response_prompts, 1):\n",
    "                lines.extend(\n",
    "                    [\n",
    "                        f\"### Response Prompt {i}\",\n",
    "                        \"```\",\n",
    "                        prompt,\n",
    "                        \"```\",\n",
    "                        \"\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        lines.append(\"---\\n\")\n",
    "\n",
    "    (log_dir / \"prompts.md\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "def save_run_logs(\n",
    "    results: list[ConversationalPipelineResult | Exception],\n",
    "    config: dict,\n",
    "    num_personas: int,\n",
    "    num_entries: int,\n",
    ") -> Path:\n",
    "    \"\"\"Save all logs for a run.\n",
    "\n",
    "    Returns:\n",
    "        Path to the log directory\n",
    "    \"\"\"\n",
    "    log_dir = get_log_dir()\n",
    "\n",
    "    # Filter successful results\n",
    "    successful = [\n",
    "        r for r in results if isinstance(r, ConversationalPipelineResult) and r.persona\n",
    "    ]\n",
    "\n",
    "    write_config_log(log_dir, config, num_personas, num_entries)\n",
    "\n",
    "    for result in successful:\n",
    "        write_persona_log(log_dir, result)\n",
    "\n",
    "    write_prompts_log(log_dir, successful)\n",
    "\n",
    "    print(f\"Logs saved to: {log_dir}\")\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conversational_results(\n",
    "    result: ConversationalPipelineResult | Exception,\n",
    ") -> None:\n",
    "    \"\"\"Display all outputs for one persona.\"\"\"\n",
    "    if isinstance(result, Exception):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"PERSONA FAILED WITH EXCEPTION:\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        print(f\"{type(result).__name__}: {result}\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"PERSONA {result.persona_id}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    if result.error:\n",
    "        print(f\"\\nError: {result.error}\")\n",
    "        return\n",
    "\n",
    "    # Persona details\n",
    "    p = result.persona\n",
    "    print(f\"\\n## Generated Persona: {p.name}\")\n",
    "    print(f\"Age: {p.age} | Profession: {p.profession} | Culture: {p.culture}\")\n",
    "    print(f\"Values: {', '.join(p.core_values)}\")\n",
    "    print(f\"Bio: {p.bio}\")\n",
    "\n",
    "    # Entries with nudges\n",
    "    for i, entry in enumerate(result.entries, 1):\n",
    "        print(f\"\\n{'─' * 40}\")\n",
    "        print(f\"### Entry {i}: {entry.initial_entry.date}\")\n",
    "        print(\n",
    "            f\"Tone: {entry.tone} | Verbosity: {entry.verbosity} | Mode: {entry.reflection_mode}\"\n",
    "        )\n",
    "        print(f\"\\n**Initial Entry:**\")\n",
    "        print(entry.initial_entry.content)\n",
    "\n",
    "        if entry.nudge:\n",
    "            print(f\"\\n**Nudge ({entry.nudge.nudge_category}):**\")\n",
    "            print(f\"Trigger: {entry.nudge.trigger_reason}\")\n",
    "            print(f'\"{entry.nudge.nudge_text}\"')\n",
    "\n",
    "            if entry.response:\n",
    "                print(f\"\\n**Response:**\")\n",
    "                print(entry.response.content)\n",
    "            else:\n",
    "                print(\"\\n*(No response)*\")\n",
    "        else:\n",
    "            print(\"\\n*(No nudge)*\")\n",
    "\n",
    "    # Summary stats\n",
    "    nudge_count = sum(1 for e in result.entries if e.nudge)\n",
    "    response_count = sum(1 for e in result.entries if e.nudge and e.response)\n",
    "    print(f\"\\n{'─' * 40}\")\n",
    "    print(f\"### Summary for {p.name}\")\n",
    "    print(f\"Total entries: {len(result.entries)}\")\n",
    "    print(f\"Nudges given: {nudge_count}\")\n",
    "    print(f\"Responses received: {response_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 5 personas with conversational journaling...\n",
      "Each persona will have 5 entries with potential nudges.\n",
      "Model: gpt-5-mini-2025-08-07 | Reasoning: high\n",
      "Start date: 2025-10-25\n",
      "Nudge probability: 0.4\n",
      "Response probability: 0.7\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PERSONA 1\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Maria Alvarez\n",
      "Age: 48 | Profession: Parent (Stay-at-home) | Culture: North American\n",
      "Values: Tradition\n",
      "Bio: Maria Alvarez keeps her mother's tamale recipe in a stained notebook and spends two full days each December making tamales for the extended family before Nochebuena; she also teaches the grandchildren a few Spanish lullabies and the old prayers her abuela used to sing. She runs the household calendar—coordinating baptisms, the neighborhood posada, and the annual cemetery visit on Dia de los Muertos—while driving her elderly father to Mass every Sunday. Lately she's worried because her eldest moved out of state, younger relatives prefer quick takeout and video calls to the long preparations she learned growing up, and the community center that hosted family gatherings closed last year.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Stream of consciousness | Verbosity: Short (1-3 sentences) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "I let everyone insist we order from the taquería instead of making tamales for Nochebuena—called for fifty, stacked the boxes beside mama's stained recipe notebook, hummed 'Arrorró' to fill the silence, and my hands trembled when I tied the last napkin.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-10-28\n",
      "Tone: Defensive | Verbosity: Short (1-3 sentences) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Folded the last load of laundry, wiped coffee from Dad's favorite mug, and answered Ana's text with a thumbs-up; hummed 'Arrorró' while I set mama's flour-speckled notebook back on the shelf. I'm not abandoning anything by calling the taquería — it's still my kitchen, my rules, and I'll teach the prayers when the kids visit.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-04\n",
      "Tone: Exhausted | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Kettle hisses; I stir my coffee and glance at the taquería boxes still on the counter beside mama's stained recipe notebook. Folded two loads of laundry, found a sock with a hole and set it in the sewing basket I never open, wiped the coffee ring off Dad's favorite mug and hummed 'Arrorró' without thinking.\n",
      "\n",
      "Ran to the store for limes and came back with everything except cilantro; put groceries away slowly and had to move three things twice. Ana texted a photo of her new couch and I sent a thumbs-up because it's faster than a call. Dad asked if I had the crossword; I found the paper under yesterday's recipes and he laughed.\n",
      "\n",
      "Sat at the table to heat leftovers; legs cramped and I left the radio on because quiet made me notice too many things. Flipped through mama's notebook even though I promised myself I'd leave it alone—spare line items, the recipe I always forget the name of, grease smudges at the edge. Hummed 'Arrorró' again, turned out the kitchen light, the house smelled like oregano.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-12\n",
      "Tone: Stream of consciousness | Verbosity: Short (1-3 sentences) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Phone buzzed—Ana video-called to show the baby's first steps; I watched part of it with a diaper in my hand and sent a thumbs-up instead of calling back, put mama's stained notebook under the breadbox and hummed 'Arrorró' until the kitchen noises felt louder than the picture.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-17\n",
      "Tone: Defensive | Verbosity: Long (Detailed reflection) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Hummed 'Arrorró' under my breath when Ana called—her voice thin, the baby fussing. Put the phone on speaker, cupped it to the crib's edge, and sang the first verse in the low cadence Mama used when she rocked us. Not dramatic, no grand announcement. The crying eased into little hiccups and Ana let out that laugh that's part relief, part astonishment.\n",
      "\n",
      "She asked how I still knew every line. I told her abuela taught us and walked her through the next few lines slowly so she could repeat. When we hung up I found the margin of mama's stained recipe notebook and wrote a couple of words next to the grease smudge—no fanfare, just a place for the song beside the tamale notes. It felt practical, mattered without needing anyone's approval.\n",
      "\n",
      "I rinsed the cup, tied a napkin the way Mama did, hummed the last line until the kitchen settled. Not showing off, not trying to prove I'm right about anything—just doing a small, ordinary thing that fits. My hands were steady enough to finish the dishes.\n",
      "\n",
      "**Nudge (elaboration):**\n",
      "Trigger: Random elaboration gate passed\n",
      "\"Which words did you add beside the tamale notes?\"\n",
      "\n",
      "**Response:**\n",
      "I wrote: 'Para Ana — guárdalo, enséñale a la niña.' Said it like a note, but what I didn't write out loud: I'm tired of being the last one who remembers. I wanted someone else to hold it when I'm done.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Maria Alvarez\n",
      "Total entries: 5\n",
      "Nudges given: 1\n",
      "Responses received: 1\n",
      "\n",
      "================================================================================\n",
      "PERSONA 2\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Mariana Torres\n",
      "Age: 31 | Profession: Gig Worker | Culture: Latin American\n",
      "Values: Universalism, Hedonism\n",
      "Bio: Mariana Torres is a 31-year-old gig worker who splits her week between bicycle food deliveries and selling limited-run prints of her street-food photography; she turned down a steady office marketing role last year so she could keep weekends free to run a monthly community supper that donates part of the proceeds to a migrant shelter and to join beach cleanups. Her earnings swing with the seasons, and a recent run of low tips forced her to cancel a planned weekend away, sharpening the constant trade-off between building an emergency fund and spending on good meals, short trips, or live shows that help her recharge. She bookmarks international petitions and organizes a neighborhood recycling drive between shifts, and often worries that her small efforts aren’t enough—so she tracks success by how many hours she can give to local projects and whether she still has room in her schedule for spontaneous nights out.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Self-reflective | Verbosity: Short (1-3 sentences) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Chain slipped at the mercado corner; I fixed it with one hand, gulped a tiny cafecito, then kept biking—three deliveries and one shy coin tip later I taped two new prints of a pupusa stall into the little gallery box Ana gave me. Ate cold arroz con pollo, checked the app balance, sighed, texted the supper volunteers.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-10-28\n",
      "Tone: Defensive | Verbosity: Long (Detailed reflection) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Helmet still on, I said yes before I thought. Ana texted from the supper: no one to man the mise en place — could I swing by? I had promised myself a cheap bus trip for the weekend, my app balance was sad, my tips were a joke. Still I locked my bike on the corner and went into the kitchen.\n",
      "\n",
      "Hands in the masa, I taught Carla how to fold the pupusas so the cheese stays inside; she kept laughing every time it tore. Someone handed me a tiny cafecito, another volunteer - Julio - brought extra limes. No big speeches, no Facebook post, just the small coordination: score plates, stack bowls, keep one eye on the rice. When the driver left with the first batch for the shelter, I didn't check the bank app for a full ten minutes.\n",
      "\n",
      "Yes, I could have taken two more deliveries and maybe saved the bus fare. I know the numbers, I count them in my head as I ride. That said, this is how I keep doing the supper, so I did it. Came home with masa under my nails, a smudge on my shirt, less cash but a quiet camaraderie in my chest that isn't loud or heroic. That was the thing I did.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-01\n",
      "Tone: Stream of consciousness | Verbosity: Medium (1-2 paragraphs) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Phone buzzing in my apron pocket, another ping from the app, I locked the bike and saw a señora on the stoop with a toddler in a blanket and three shopping bags. One bag split; rice tumbled out and the kid started crying. I dropped the thermal bag, grabbed the torn one, hauled it up two flights with my left hand while my helmet dangled on my elbow. She kept saying gracias; the kid pointed at the camera on my shoulder and shouted 'fotito.'\n",
      "\n",
      "She shoved a tiny cafecito at me like payment; I took two hot sips, left a small print of a gordita photo on their counter because the kid kept pointing, then pedaled away. I checked the app only later; for those twenty minutes the numbers were quiet. No speeches, no selfies, just doing the thing, messy and small.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-07\n",
      "Tone: Self-reflective | Verbosity: Short (1-3 sentences) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Helmet still warm from the last run, I clipped a new print into Ana's little box, answered a ping and handed a cafecito to a señora who insisted—two deliveries, one tiny tip, one polite gracias. Biked home with masa smudges on my thumb, checked the supper chat and said yes to cover mise en place next weekend.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-13\n",
      "Tone: Emotional/Venting | Verbosity: Long (Detailed reflection) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Halfway through tucking a fresh ceviche print into the little gallery box on the corner, a kid from the bodega tugged my sleeve and asked if I'd look at his portfolio. His phone had died, the school's deadline was tomorrow, and his hands were full of photocopies. My thumb itched for the app—bus fare, two quick orders—but I closed the box and said okay.\n",
      "\n",
      "We sat on the stoop, elbows on knees, and I showed him how to frame a plate so the texture reads: get low, steady, wait for a stray hand or a lime wedge. He tried, cursed softly, then laughed when his first shot caught a señora's foot instead of the fritanga. We took three honest photos, I picked the clearest and slid one of my small prints into his portfolio. He whispered gracias like it was currency.\n",
      "\n",
      "Rode off with the app balance unchanged, a little less cash and a small warm feeling in my chest. Not a big heroic thing—just the quiet doing I try to keep, one tiny, steady give after another.\n",
      "\n",
      "**Nudge (elaboration):**\n",
      "Trigger: Random elaboration gate passed\n",
      "\"Which photo did you pick?\"\n",
      "\n",
      "*(No response)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Mariana Torres\n",
      "Total entries: 5\n",
      "Nudges given: 1\n",
      "Responses received: 0\n",
      "\n",
      "================================================================================\n",
      "PERSONA 3\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Carlos Morales\n",
      "Age: 30 | Profession: Gig Worker | Culture: North American\n",
      "Values: Tradition, Security\n",
      "Bio: Carlos grew up in a multigenerational household where Sunday dinners center on his grandmother's tamales and the family speaks Spanish at the table; after his mother became chronically ill he took on scheduling her doctor appointments and managing household bills. He works as a rideshare and grocery-delivery driver, booking the same morning shifts and keeping a spreadsheet of regular clients and monthly earnings, with a separate savings account labeled \"buffer\" and a private supplemental health plan to cover gaps in platform benefits. Recent cuts to per-ride rates and pressure from siblings to move to the city for higher pay have made it harder to cover his mother's prescriptions and the small bungalow the family has lived in for decades, so he has turned down long-distance contracts that would uproot the household and is saving toward a down payment while teaching his niece the tamale recipe he learned.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Defensive | Verbosity: Long (Detailed reflection) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "The masa slid off the table and landed in a half-circle on the linoleum. My first instinct wasn't to yell. I swore under my breath, wiped my hands, and told my niece to come closer. We salvaged what we could—added water, a little oil, folded it tighter. Abuela's paper wrappers are stained, the kitchen smelled of cumin and onion, and for a minute the house felt like Sundays again. I could've snapped; didn't.\n",
      "\n",
      "Phone buzzed: an agency asking if I'd take a three-day out-of-state contract. Good money. I told them no, not because I'm martyred but because Mom needed her refill and the bungalow needs the small repairs I can't ignore. I counted the numbers in my head—'buffer' still tight—said 'no thanks' and hung up. Felt weirdly normal to refuse money for something that would have broken the rhythm here.\n",
      "\n",
      "Niece finished her first tamal and grinned; she didn't know she'd done something mostly right. I didn't announce anything to my siblings, just sent a text explaining the decision because they'll ask. No fanfare. Just folded masa, logged the morning's earnings in the spreadsheet later, and went to help Mom with her meds. Small. Ordinary. Felt like the version of me I want—steady, stubborn, not always choosing the easy cash. Not noble. Just how I need to be.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-10-28\n",
      "Tone: Brief and factual | Verbosity: Short (1-3 sentences) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Pharmacy called—insurance denied Mom's refill. I drove over, paid the $32 difference from the 'buffer' account, asked the tech to resubmit the claim, logged it in the spreadsheet, reheated tamales for Mom and didn't make a thing of it.\n",
      "\n",
      "**Nudge (grounding):**\n",
      "Trigger: Grounded entry but brief - invite specifics\n",
      "\"How did the tamales taste?\"\n",
      "\n",
      "*(No response)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-03\n",
      "Tone: Exhausted | Verbosity: Short (1-3 sentences) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "My eyes were heavy but I took the long airport run anyway even though I'd promised to be home for my niece's tamal lesson; told her we'd make more tomorrow. She finished her tamal and grinned; I logged the surge in the spreadsheet in the passenger seat and didn't say anything.\n",
      "\n",
      "**Nudge (elaboration):**\n",
      "Trigger: Random elaboration gate passed\n",
      "\"What made you take the long airport run?\"\n",
      "\n",
      "**Response:**\n",
      "I don't know, maybe habit and extra hours. She's okay.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-10\n",
      "Tone: Self-reflective | Verbosity: Short (1-3 sentences) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "App buzzed with a long run and my thumb hovered; I closed it, taught my niece to press the masa so it wouldn't tear, reheated a plate for Mom, then logged the missed fare in the spreadsheet.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-15\n",
      "Tone: Brief and factual | Verbosity: Medium (1-2 paragraphs) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Spreadsheet matched the bank—small relief. Morning blocks were all short runs: a quick passenger, two grocery drops that turned into stair duty, and a longer wait at a deli. Filled the tank between fares, logged every tip and toll, and ignored the app's long-route offers until they stopped pinging.\n",
      "\n",
      "Back home, made coffee, checked Mom's pills and set a reminder for the refill. Topped up a little in the 'buffer' and adjusted the down-payment column in the spreadsheet while my niece did homework at the kitchen table. Siblings sent city listings; I read them and didn't answer. Nothing dramatic—just keeping the numbers honest and the house running.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Carlos Morales\n",
      "Total entries: 5\n",
      "Nudges given: 2\n",
      "Responses received: 1\n",
      "\n",
      "================================================================================\n",
      "PERSONA 4\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Layla Hassan\n",
      "Age: 48 | Profession: Software Engineer | Culture: Middle Eastern\n",
      "Values: Tradition\n",
      "Bio: Layla Hassan, 48, is a senior software engineer at a national bank in Amman who has worked there for 22 years and acts as a mentor to junior developers, insisting they learn the team's legacy codebase and documentation practices. Every Ramadan she organizes nightly iftar at her parents' home and spends weekends teaching her teenage children the family recipes and classical Arabic poems, and she worries when they prefer social plans over family gatherings. She resisted when management proposed migrating the bank's core system to a cloud-first stack because she feared losing long-maintained workflows and the young engineers' chance to learn the older systems; she now splits time between training newcomers and preserving the department's institutional documentation. Her main goal is to keep the family's seasonal cooking and holiday rites alive and to convince her children to keep the same rites when they start their own families.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Brief and factual | Verbosity: Medium (1-2 paragraphs) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Explaining the nightly mainframe sequence to Tarek, I dug out the yellowing printouts from the shelf and pointed at the old flowchart while he asked why we still run certain reports. He tried a command, it failed, we traced the batch job through three scripts, I read aloud the commented Arabic note my predecessor had left—small handwriting about a Ramadan freeze from years ago—and it clicked for him. He didn't need me to tell him what to think; he needed the map.\n",
      "\n",
      "I stayed until his test passed, scanned the printouts into the repo, and left a short note in the runbook about the corner cases. It was ordinary: patient, practical, stubborn about preserving traces. On the drive home I thought of my mother's hands teaching me maqluba—step by step until the rhythm sticks—and felt a quiet alignment with the person I want to be.\n",
      "\n",
      "**Nudge (elaboration):**\n",
      "Trigger: Random elaboration gate passed\n",
      "\"Which corner cases did you note in the runbook?\"\n",
      "\n",
      "*(No response)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-11-02\n",
      "Tone: Emotional/Venting | Verbosity: Medium (1-2 paragraphs) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Karim knocked and said the release had to ship; there was one legacy report I'd always made them test against the old job. He'd written a quick rewrite and CI was green. I told him to merge and moved on. I didn't pull the yellow printouts off the shelf, I didn't read the faded Arabic note left for me. I signed the change off at the meeting table and let the sprint carry on.\n",
      "\n",
      "It sits wrong. My chest tightens when I picture that small handwriting and the margin notes I never scanned. I feel foolish and impatient and quietly ashamed, no fanfare, just a small ache as I drive home thinking of the maqluba I planned to teach the children this weekend and wondering whether I'll bother to insist on the recipe tomorrow.\n",
      "\n",
      "**Nudge (elaboration):**\n",
      "Trigger: Random elaboration gate passed\n",
      "\"What did the faded Arabic note say?\"\n",
      "\n",
      "*(No response)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-11\n",
      "Tone: Brief and factual | Verbosity: Medium (1-2 paragraphs) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Saw Karim's refactor remove a tiny conditional that still mattered for month-end reconciliation. Instead of rubber-stamping the merge I reproduced the edge case, wrote a two-line note in Arabic in the runbook and added a failing test so the behaviour is explicit for whoever comes after me. Pushed the change with a short commit message and went home without making a scene.\n",
      "\n",
      "At dinner I told the children about the fuss between commits and cautions, then asked them to help peel the eggplants for maqluba. My daughter surprised me by reciting a line of al-Mutanabbi while we worked and nobody argued about going out. Small, ordinary, useful.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-21\n",
      "Tone: Brief and factual | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "The build passed before I finished my second cup of coffee. Karim sent the merge request; it looked tidy but I traced the related ledger output anyway. Found a minor rounding mismatch that affects month-end reconciliation — added a concise note in the runbook, wrote a small unit test, and asked a junior to include the case in the next test pass. Pairing felt ordinary: screen, terminal, quiet questions, his nods when the pieces fit.\n",
      "\n",
      "Lunch was a warm bowl of mujadara at my desk while I worked through a backlog of tickets; a colleague grumbled about the ones labeled 'legacy' as if that were an insult. I pointed him to the archive and to the doc that traces the monthly reports. After work I made a quick stewed chicken with lemon and cumin; the children grabbed plates and said they had plans. I asked if they'd help with folding the pastry tomorrow and they said maybe, which is my kind of compromise.\n",
      "\n",
      "I spent the last hour tidying documentation: uploaded a screenshot of the reconciliation output, clarified a heading, and left a short commit message. Called mother to ask about a small trick with the pastry — she laughed and used her usual shorthand, 'a handful, not a measuring cup,' so I wrote it down more exact. Dishes in the sink, lights dimmed in the living room, no drama. Nothing big, no decisions, only the slow drag of routine.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-23\n",
      "Tone: Self-reflective | Verbosity: Long (Detailed reflection) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Karim pushed the merge and I almost hit approve—old reflex to keep the sprint moving. The diff touched the nightly ledger mapping and something in my chest tightened. I reached for the thin folder with the old prints, flipped to the page with my predecessor's tiny Arabic scrawl about month-end ordering, and brought my laptop over. I reran the batch, reproduced the mismatch, and called a junior over. We traced the index through three scripts the way I've taught them to trace things: small steps, don't guess. She typed the failing test, I added a two-line note in Arabic in the runbook so the context isn't only in my head, then I merged the MR and left without drama.\n",
      "\n",
      "On the drive home I thought of my mother's 'قبضة'—how she taught me to judge salt by the handful, not the cup. At the kitchen counter tonight the children were halfway out the door but when I asked for help folding pastry they lingered; my daughter hummed a line of al-Mutanabbi and we worked in silence more comfortable than talk.\n",
      "\n",
      "Not a showy thing: a scan, a test, a short note, two people learning the same corner. It felt right in a plain way, like a recipe I know by heart and still teach slowly.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Layla Hassan\n",
      "Total entries: 5\n",
      "Nudges given: 2\n",
      "Responses received: 0\n",
      "\n",
      "================================================================================\n",
      "PERSONA 5\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Daniel Hayes\n",
      "Age: 49 | Profession: Software Engineer | Culture: North American\n",
      "Values: Achievement, Stimulation\n",
      "Bio: Daniel Hayes, 49, is a Software Engineer who left a stable senior role at a major cloud company two years ago to lead platform architecture at a mid-stage startup; he keeps a spreadsheet tracking promotion milestones, open-source contributions, GitHub stars, conference talks, and monthly production metrics, and adds industry certifications to his CV every year. He alternates intense sprints at the startup with hackathons, client-facing incident responses, and weekend climbing trips, switches programming languages regularly (recently picked up Rust), and takes short consulting gigs to keep his work from becoming maintenance-heavy. The long hours, frequent project changes, and missed family events have strained his marriage, and he grows visibly frustrated when team reviews omit public recognition or when a role settles into predictable, repetitive tasks.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Brief and factual | Verbosity: Short (1-3 sentences) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Cut off my own explanation mid-sentence, pointed to Priya and said \"that was her work,\" then shut up and let her field the questions; small, quiet move, and exactly the version of myself I want to be.\n",
      "\n",
      "**Nudge (grounding):**\n",
      "Trigger: Grounded entry but brief - invite specifics\n",
      "\"Where did you feel that small, quiet move?\"\n",
      "\n",
      "**Response:**\n",
      "In my chest and throat — jaw unclenched, shoulders dropped a notch. Quiet, satisfied calm; like finally OK not owning the spotlight.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-11-04\n",
      "Tone: Defensive | Verbosity: Short (1-3 sentences) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "—argued in the incident channel that the regression wasn't my Rust microchange (logs prove it), felt the familiar edge when nobody acknowledged it; updated the promotion tracker, pushed a small PR, drank bad office coffee, and pretended the backlog wasn't quietly turning into maintenance.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-12\n",
      "Tone: Defensive | Verbosity: Short (1-3 sentences) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Hands clenched for a second when the PM suggested our team absorb another spike; left a terse rationale in the ticket and walked away. Spent the afternoon chasing flaky tests, merged a small PR, ate a lukewarm sandwich at my desk, and updated the spreadsheet out of habit before logging off.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-22\n",
      "Tone: Exhausted | Verbosity: Long (Detailed reflection) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Fingers hovered over the merge button on a three-line PR labeled \"temp mitigation\"—an if that short-circuited the new auth flow and silenced the 500s. On the stand-up the PM kept saying \"ship something\" until my throat tightened; I had a proper rollback and a clean patch drafted that would have taken half a day to land with tests, but the clock felt loud. I typed the smallest change that would stop the noise, dropped a big TODO in the code, and merged.\n",
      "\n",
      "It calmed the pager. Ops wrote thanks. I put a short note in the incident thread, opened a follow-up ticket, and told the team we'd address it in the next cycle. I didn't run the full integration suite—locally it still flakes—and I skipped the extra refactor that would have made the change right. Priya pinged to ask if we'd need more context; I answered quickly and closed the tab.\n",
      "\n",
      "Left the office with a paper cup of bad coffee, updated the promotion tracker because it's what I do when conversation is thin, and then went climbing to try and forget. My hands were fine on the rock; my mind kept going back to that merged commit. It worked. It feels off.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Hedging language detected in unsettled entry\n",
      "\"Did skipping the integration suite feel off?\"\n",
      "\n",
      "**Response:**\n",
      "Yes. Felt like papering over a crack—quieted the pager but left a gnawing tech-debt aftertaste. Need to carve out time next cycle to do it right.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-26\n",
      "Tone: Brief and factual | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Hit snooze twice, dragged a hoodie on, checked the incident channel before coffee. A handful of 500s flagged an auth timeout - ran the quick mitigation I keep in a gist, dropped a three-line patch, left a TODO and a follow-up ticket. Ops wrote thanks; I didn't run the full integration suite because the flakiness still hangs. Small relief, same compromise.\n",
      "\n",
      "Spent the morning on code reviews: two lint fixes, a doc tweak, a tiny perf suggestion on Priya's service (left the note and let her own it). Had a 1:1 where I read aloud from the promotion tracker to remember what I'm chasing; updated an entry for a small OSS PR and added a certification renewal to the list. Ate a cold sandwich at my desk while prototyping a Rust parser for fifteen minutes — pleasant distraction.\n",
      "\n",
      "Closed the laptop with the spreadsheet up, emailed a short status to the PM and walked to the climbing gym. Fingers felt solid on easy routes; it was the kind of endurance work that quiets the hands. Home, my partner was on the couch and we argued about groceries; I lost. Opened a tab to look at flaky tests and fell asleep before I could run them. Nothing dramatic.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Daniel Hayes\n",
      "Total entries: 5\n",
      "Nudges given: 2\n",
      "Responses received: 2\n",
      "Logs saved to: ../logs/synthetic_data/2026-01-05_19-24-01\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "Successfully generated: 5/5 personas\n",
      "Total entries: 25\n",
      "Total nudges given: 8\n",
      "Total responses: 4\n",
      "Response rate: 50.0%\n",
      "\n",
      "Logs saved to: ../logs/synthetic_data/2026-01-05_19-24-01\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "NUM_PERSONAS = 5\n",
    "NUM_ENTRIES = 5\n",
    "START_DATE = \"2025-10-25\"\n",
    "\n",
    "print(f\"Generating {NUM_PERSONAS} personas with conversational journaling...\")\n",
    "print(f\"Each persona will have {NUM_ENTRIES} entries with potential nudges.\")\n",
    "print(f\"Model: {MODEL_NAME} | Reasoning: {DEFAULT_REASONING_EFFORT}\")\n",
    "print(f\"Start date: {START_DATE}\")\n",
    "print(f\"Nudge probability: {config['nudge']['base_probability']}\")\n",
    "print(f\"Response probability: {config['nudge']['response_probability']}\\n\")\n",
    "\n",
    "# Run all personas in parallel\n",
    "results = await run_parallel_conversational_personas(\n",
    "    num_personas=NUM_PERSONAS,\n",
    "    config=config,\n",
    "    schwartz_config=schwartz_config,\n",
    "    num_entries=NUM_ENTRIES,\n",
    "    start_date=START_DATE,\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    display_conversational_results(result)\n",
    "\n",
    "# Save logs\n",
    "successful_results = [\n",
    "    r for r in results if isinstance(r, ConversationalPipelineResult) and r.persona\n",
    "]\n",
    "log_dir = save_run_logs(results, config, NUM_PERSONAS, NUM_ENTRIES)\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"FINAL SUMMARY\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"Successfully generated: {len(successful_results)}/{NUM_PERSONAS} personas\")\n",
    "\n",
    "total_entries = sum(len(r.entries) for r in successful_results)\n",
    "total_nudges = sum(sum(1 for e in r.entries if e.nudge) for r in successful_results)\n",
    "total_responses = sum(\n",
    "    sum(1 for e in r.entries if e.nudge and e.response) for r in successful_results\n",
    ")\n",
    "\n",
    "print(f\"Total entries: {total_entries}\")\n",
    "print(f\"Total nudges given: {total_nudges}\")\n",
    "print(f\"Total responses: {total_responses}\")\n",
    "if total_nudges > 0:\n",
    "    print(f\"Response rate: {total_responses / total_nudges:.1%}\")\n",
    "print(f\"\\nLogs saved to: {log_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
