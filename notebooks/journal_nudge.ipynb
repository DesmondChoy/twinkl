{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Journal Generation with Nudging\n",
    "\n",
    "This notebook extends the synthetic journal generation with a two-way conversational nudging system.\n",
    "When an entry is vague or potentially rich with unexplored tension, the system responds with a brief nudge that invites elaboration.\n",
    "\n",
    "**Design goal**: Nudges should feel like natural curiosity from a thoughtful companion, not interrogation or therapy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import yaml\n",
    "import polars as pl\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from openai import AsyncOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "# Add project root to path for prompts module\n",
    "PROJECT_ROOT = (\n",
    "    Path(__file__).parent.parent if \"__file__\" in dir() else Path.cwd().parent\n",
    ")\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check for API Key\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"WARNING: OPENAI_API_KEY not found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configs loaded successfully.\n",
      "Available Persona Attributes: ['age_ranges', 'cultures', 'professions', 'schwartz_values']\n",
      "Schwartz Values with elaborations: ['Self-Direction', 'Stimulation', 'Hedonism', 'Achievement', 'Power', 'Security', 'Conformity', 'Tradition', 'Benevolence', 'Universalism']\n",
      "Nudge config loaded: ['response_probability', 'response_modes', 'min_words', 'max_words']\n"
     ]
    }
   ],
   "source": [
    "# Configuration Loading\n",
    "CONFIG_PATH = Path(\"config/synthetic_data.yaml\")\n",
    "if not CONFIG_PATH.exists():\n",
    "    CONFIG_PATH = Path(\"../config/synthetic_data.yaml\")\n",
    "\n",
    "SCHWARTZ_VALUES_PATH = Path(\"config/schwartz_values.yaml\")\n",
    "if not SCHWARTZ_VALUES_PATH.exists():\n",
    "    SCHWARTZ_VALUES_PATH = Path(\"../config/schwartz_values.yaml\")\n",
    "\n",
    "\n",
    "def load_config(path: str | Path) -> dict:\n",
    "    with open(path, \"r\") as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "\n",
    "config = load_config(CONFIG_PATH)\n",
    "schwartz_config = load_config(SCHWARTZ_VALUES_PATH)\n",
    "\n",
    "print(\"Configs loaded successfully.\")\n",
    "print(f\"Available Persona Attributes: {list(config['personas'].keys())}\")\n",
    "print(f\"Schwartz Values with elaborations: {list(schwartz_config['values'].keys())}\")\n",
    "print(f\"Nudge config loaded: {list(config['nudge'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Models\n",
    "\n",
    "Extended models for conversational journaling with nudges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base models (from journal_gen.ipynb)\n",
    "class Persona(BaseModel):\n",
    "    name: str = Field(description=\"Full name of the persona\")\n",
    "    age: str\n",
    "    profession: str\n",
    "    culture: str\n",
    "    core_values: list[str] = Field(description=\"Top 3 Schwartz values\")\n",
    "    bio: str = Field(\n",
    "        description=\"A short paragraph describing their background, stressors, and goals\"\n",
    "    )\n",
    "\n",
    "\n",
    "class JournalEntry(BaseModel):\n",
    "    \"\"\"LLM-generated journal entry. Metadata (tone, verbosity, etc.) tracked separately.\"\"\"\n",
    "\n",
    "    date: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "# New models for conversational pipeline\n",
    "# Note: \"grounding\" was removed because it relied on reflection_mode metadata\n",
    "# which is synthetic generation data not available in production (metadata leakage)\n",
    "NudgeCategory = Literal[\"clarification\", \"elaboration\", \"tension_surfacing\"]\n",
    "\n",
    "\n",
    "class NudgeResult(BaseModel):\n",
    "    \"\"\"Generated nudge with metadata.\"\"\"\n",
    "\n",
    "    nudge_text: str\n",
    "    nudge_category: NudgeCategory\n",
    "    trigger_reason: str  # Why this nudge was generated\n",
    "    was_responded_to: bool = False\n",
    "\n",
    "\n",
    "class JournalTurn(BaseModel):\n",
    "    \"\"\"A single turn in the conversation (entry or response).\"\"\"\n",
    "\n",
    "    date: str\n",
    "    content: str\n",
    "    turn_type: Literal[\"initial_entry\", \"nudge_response\"]\n",
    "    responding_to_nudge: str | None = None  # The nudge text if this is a response\n",
    "\n",
    "\n",
    "class ConversationalEntry(BaseModel):\n",
    "    \"\"\"Complete conversational exchange for one journaling session.\"\"\"\n",
    "\n",
    "    initial_entry: JournalEntry\n",
    "    nudge: NudgeResult | None = None\n",
    "    response: JournalTurn | None = None  # User's response to the nudge\n",
    "    # Metadata\n",
    "    tone: str\n",
    "    verbosity: str\n",
    "    reflection_mode: str\n",
    "\n",
    "\n",
    "# JSON schemas for OpenAI structured output\n",
    "PERSONA_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"string\"},\n",
    "        \"profession\": {\"type\": \"string\"},\n",
    "        \"culture\": {\"type\": \"string\"},\n",
    "        \"core_values\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"bio\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\", \"profession\", \"culture\", \"core_values\", \"bio\"],\n",
    "}\n",
    "\n",
    "JOURNAL_ENTRY_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"date\": {\"type\": \"string\"},\n",
    "        \"content\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"date\", \"content\"],\n",
    "}\n",
    "\n",
    "NUDGE_DECISION_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"decision\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"no_nudge\", \"clarification\", \"elaboration\", \"tension_surfacing\"],\n",
    "        },\n",
    "        \"reason\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"decision\", \"reason\"],\n",
    "}\n",
    "\n",
    "NUDGE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"nudge_text\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"nudge_text\"],\n",
    "}\n",
    "\n",
    "NUDGE_RESPONSE_SCHEMA = {\n",
    "    \"type\": \"object\",\n",
    "    \"additionalProperties\": False,\n",
    "    \"properties\": {\n",
    "        \"content\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"content\"],\n",
    "}\n",
    "\n",
    "PERSONA_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"Persona\",\n",
    "    \"schema\": PERSONA_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "JOURNAL_ENTRY_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"JournalEntry\",\n",
    "    \"schema\": JOURNAL_ENTRY_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "NUDGE_DECISION_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"NudgeDecision\",\n",
    "    \"schema\": NUDGE_DECISION_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "NUDGE_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"Nudge\",\n",
    "    \"schema\": NUDGE_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}\n",
    "\n",
    "NUDGE_RESPONSE_RESPONSE_FORMAT = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"name\": \"NudgeResponse\",\n",
    "    \"schema\": NUDGE_RESPONSE_SCHEMA,\n",
    "    \"strict\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_value_context(values: list[str], schwartz_config: dict) -> str:\n",
    "    \"\"\"Build rich context about Schwartz values for persona generation.\n",
    "\n",
    "    Args:\n",
    "        values: List of Schwartz value names (e.g., [\"Achievement\", \"Benevolence\"])\n",
    "        schwartz_config: The loaded schwartz_values.yaml config\n",
    "\n",
    "    Returns:\n",
    "        Formatted string with value elaborations for prompt injection\n",
    "    \"\"\"\n",
    "    context_parts = []\n",
    "\n",
    "    for value_name in values:\n",
    "        if value_name not in schwartz_config[\"values\"]:\n",
    "            continue\n",
    "\n",
    "        v = schwartz_config[\"values\"][value_name]\n",
    "\n",
    "        # Build a focused context block for this value\n",
    "        context_parts.append(f\"\"\"\n",
    "### {value_name}\n",
    "**Core Motivation:** {v[\"core_motivation\"].strip()}\n",
    "\n",
    "**How this manifests in behavior:**\n",
    "{chr(10).join(f\"- {b}\" for b in v[\"behavioral_manifestations\"][:5])}\n",
    "\n",
    "**Life domain expressions:**\n",
    "- Work: {v[\"life_domain_expressions\"][\"work\"].strip()}\n",
    "- Relationships: {v[\"life_domain_expressions\"][\"relationships\"].strip()}\n",
    "\n",
    "**Typical stressors for this person:**\n",
    "{chr(10).join(f\"- {s}\" for s in v[\"typical_stressors\"][:4])}\n",
    "\n",
    "**Typical goals:**\n",
    "{chr(10).join(f\"- {g}\" for g in v[\"typical_goals\"][:3])}\n",
    "\n",
    "**Internal conflicts they may experience:**\n",
    "{v[\"internal_conflicts\"].strip()}\n",
    "\n",
    "**Narrative guidance:**\n",
    "{v[\"persona_narrative_guidance\"].strip()}\n",
    "\"\"\")\n",
    "\n",
    "    return \"\\n\".join(context_parts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt templates are stored in prompts/ folder as YAML files\n",
    "# See prompts/__init__.py for the loader utility\n",
    "from prompts import (\n",
    "    persona_generation_prompt,\n",
    "    journal_entry_prompt,\n",
    "    nudge_decision_prompt,\n",
    "    nudge_generation_prompt,\n",
    "    nudge_response_prompt,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Client Setup\n",
    "\n",
    "Using `gpt-5-mini`. \n",
    "\n",
    "**Note:** GPT-5 models do not support `temperature` or `top_p` parameters. Instead, use the `reasoning` parameter to control how much the model \"thinks\" before responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = AsyncOpenAI()\n",
    "MODEL_NAME = \"gpt-5-mini-2025-08-07\"\n",
    "# MODEL_NAME = \"gpt-5-nano-2025-08-07\"\n",
    "\n",
    "# Type alias for reasoning effort levels\n",
    "ReasoningEffort = Literal[\"minimal\", \"low\", \"medium\", \"high\"]\n",
    "\n",
    "# Default reasoning effort - change this to affect all generations\n",
    "DEFAULT_REASONING_EFFORT: ReasoningEffort = \"high\"\n",
    "\n",
    "\n",
    "async def generate_completion(\n",
    "    prompt: str,\n",
    "    response_format: dict | None = None,\n",
    ") -> str | None:\n",
    "    \"\"\"Generate a completion using the OpenAI Responses API (async).\n",
    "\n",
    "    Uses DEFAULT_REASONING_EFFORT to control how much the model \"thinks\".\n",
    "    Valid reasoning effort values: \"minimal\", \"low\", \"medium\", \"high\".\n",
    "    \"\"\"\n",
    "    try:\n",
    "        kwargs = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"input\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "            \"reasoning\": {\"effort\": DEFAULT_REASONING_EFFORT},\n",
    "        }\n",
    "\n",
    "        if response_format:\n",
    "            kwargs[\"text\"] = {\"format\": response_format}\n",
    "\n",
    "        response = await client.responses.create(**kwargs)\n",
    "        return response.output_text\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating completion: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _verbosity_targets(verbosity: str) -> tuple[int, int, int]:\n",
    "    \"\"\"Returns (min_words, max_words, max_paragraphs) as guidance for the LLM.\"\"\"\n",
    "    normalized = verbosity.strip().lower()\n",
    "    if normalized.startswith(\"short\"):\n",
    "        return 25, 80, 1\n",
    "    if normalized.startswith(\"medium\"):\n",
    "        return 90, 180, 2\n",
    "    return 160, 260, 3\n",
    "\n",
    "\n",
    "def _build_banned_pattern(banned_terms: list[str]) -> re.Pattern:\n",
    "    \"\"\"Build regex pattern to detect banned Schwartz value terms.\"\"\"\n",
    "    escaped = [re.escape(term) for term in banned_terms if term.strip()]\n",
    "    if not escaped:\n",
    "        return re.compile(r\"$^\")\n",
    "    return re.compile(r\"(?i)\\b(\" + \"|\".join(escaped) + r\")\\b\")\n",
    "\n",
    "\n",
    "def count_words(text: str) -> int:\n",
    "    \"\"\"Count words in text.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "\n",
    "def weighted_choice(weights: dict[str, float]) -> str:\n",
    "    \"\"\"Make a weighted random choice from a dict of {option: weight}.\"\"\"\n",
    "    options = list(weights.keys())\n",
    "    probs = list(weights.values())\n",
    "    total = sum(probs)\n",
    "    probs = [p / total for p in probs]  # Normalize\n",
    "    return random.choices(options, weights=probs, k=1)[0]\n",
    "\n",
    "\n",
    "def generate_date_sequence(\n",
    "    start_date: str, num_entries: int, min_days: int = 2, max_days: int = 10\n",
    ") -> list[str]:\n",
    "    \"\"\"Generate a sequence of dates with random intervals.\n",
    "\n",
    "    Args:\n",
    "        start_date: Starting date in YYYY-MM-DD format\n",
    "        num_entries: Number of dates to generate\n",
    "        min_days: Minimum days between entries\n",
    "        max_days: Maximum days between entries\n",
    "\n",
    "    Returns:\n",
    "        List of date strings in YYYY-MM-DD format\n",
    "    \"\"\"\n",
    "    dates = []\n",
    "    current = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "    for i in range(num_entries):\n",
    "        dates.append(current.strftime(\"%Y-%m-%d\"))\n",
    "        if i < num_entries - 1:\n",
    "            days_gap = random.randint(min_days, max_days)\n",
    "            current += timedelta(days=days_gap)\n",
    "\n",
    "    return dates\n",
    "\n",
    "\n",
    "# Banned terms include Schwartz value labels AND derivative adjectives\n",
    "SCHWARTZ_BANNED_TERMS = [\n",
    "    # Value labels\n",
    "    \"Self-Direction\",\n",
    "    \"Stimulation\",\n",
    "    \"Hedonism\",\n",
    "    \"Achievement\",\n",
    "    \"Power\",\n",
    "    \"Security\",\n",
    "    \"Conformity\",\n",
    "    \"Tradition\",\n",
    "    \"Benevolence\",\n",
    "    \"Universalism\",\n",
    "    # Derivative adjectives and related terms\n",
    "    \"self-directed\",\n",
    "    \"autonomous\",\n",
    "    \"stimulating\",\n",
    "    \"excited\",\n",
    "    \"hedonistic\",\n",
    "    \"hedonist\",\n",
    "    \"pleasure-seeking\",\n",
    "    \"achievement-oriented\",\n",
    "    \"ambitious\",\n",
    "    \"powerful\",\n",
    "    \"authoritative\",\n",
    "    \"secure\",\n",
    "    \"conformist\",\n",
    "    \"conforming\",\n",
    "    \"traditional\",\n",
    "    \"traditionalist\",\n",
    "    \"benevolent\",\n",
    "    \"kind-hearted\",\n",
    "    \"universalistic\",\n",
    "    \"altruistic\",\n",
    "    # Meta terms\n",
    "    \"Schwartz\",\n",
    "    \"values\",\n",
    "    \"core values\",\n",
    "]\n",
    "\n",
    "BANNED_PATTERN = _build_banned_pattern(SCHWARTZ_BANNED_TERMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nudge Decision Logic\n",
    "\n",
    "LLM-based classification to decide whether to nudge and which category.\n",
    "\n",
    "The LLM analyzes entry content semantically to detect:\n",
    "- **clarification** — Entry too vague to understand\n",
    "- **elaboration** — Solid entry with unexplored depth  \n",
    "- **tension_surfacing** — Hints at unresolved conflict\n",
    "- **no_nudge** — Entry is complete and grounded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test vague entry: should_nudge=True, category=clarification, reason=Too vague and brief; no details about causes, events, or emotions—needs clarification.\n",
      "Test hedging entry: should_nudge=True, category=tension_surfacing, reason=Hedging language ('I guess', 'It was fine') suggests unresolved feelings despite scheduling resolution.\n"
     ]
    }
   ],
   "source": [
    "async def decide_nudge_llm(\n",
    "    entry: JournalEntry,\n",
    "    previous_entries: list[ConversationalEntry] | None,\n",
    "    config: dict,\n",
    ") -> tuple[bool, NudgeCategory | None, str | None]:\n",
    "    \"\"\"LLM-based nudge decision (replaces regex approach).\n",
    "\n",
    "    Uses semantic understanding to classify entries instead of pattern matching.\n",
    "    The LLM evaluates vagueness, tension, and elaboration opportunities.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (should_nudge, nudge_category, trigger_reason)\n",
    "    \"\"\"\n",
    "    # Anti-annoyance: session cap (2 nudges in last 3 entries)\n",
    "    # Keep as code-based policy check, not content analysis\n",
    "    if previous_entries:\n",
    "        recent_nudge_count = sum(\n",
    "            1 for e in previous_entries[-3:] if e.nudge is not None\n",
    "        )\n",
    "        if recent_nudge_count >= 2:\n",
    "            return False, None, None\n",
    "\n",
    "    # Format previous entries for context\n",
    "    prev_entries_data = None\n",
    "    if previous_entries:\n",
    "        prev_entries_data = [\n",
    "            {\"date\": e.initial_entry.date, \"content\": e.initial_entry.content}\n",
    "            for e in previous_entries[-3:]\n",
    "        ]\n",
    "\n",
    "    prompt = nudge_decision_prompt.render(\n",
    "        entry_content=entry.content,\n",
    "        entry_date=entry.date,\n",
    "        previous_entries=prev_entries_data,\n",
    "    )\n",
    "\n",
    "    raw_json = await generate_completion(prompt, NUDGE_DECISION_RESPONSE_FORMAT)\n",
    "    if not raw_json:\n",
    "        return False, None, None\n",
    "\n",
    "    data = json.loads(raw_json)\n",
    "    decision = data.get(\"decision\", \"no_nudge\")\n",
    "    reason = data.get(\"reason\", \"\")\n",
    "\n",
    "    if decision == \"no_nudge\":\n",
    "        return False, None, None\n",
    "\n",
    "    return True, decision, reason\n",
    "\n",
    "\n",
    "# Test the LLM-based decision logic\n",
    "async def test_nudge_decision():\n",
    "    test_entry = JournalEntry(date=\"2024-01-15\", content=\"Feeling off today.\")\n",
    "    should, category, reason = await decide_nudge_llm(test_entry, None, config)\n",
    "    print(\n",
    "        f\"Test vague entry: should_nudge={should}, category={category}, reason={reason}\"\n",
    "    )\n",
    "\n",
    "    test_entry2 = JournalEntry(\n",
    "        date=\"2024-01-15\",\n",
    "        content=\"Had a meeting with the team about the project deadline. It was fine, I guess. We sorted out the schedule.\",\n",
    "    )\n",
    "    should2, category2, reason2 = await decide_nudge_llm(test_entry2, None, config)\n",
    "    print(\n",
    "        f\"Test hedging entry: should_nudge={should2}, category={category2}, reason={reason2}\"\n",
    "    )\n",
    "\n",
    "\n",
    "await test_nudge_decision()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nudge Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def generate_nudge(\n",
    "    entry: JournalEntry,\n",
    "    category: NudgeCategory,\n",
    "    previous_entries: list[ConversationalEntry] | None,\n",
    "    config: dict,\n",
    "    max_attempts: int = 2,\n",
    ") -> tuple[str | None, str]:\n",
    "    \"\"\"Generate a nudge for the given entry.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (nudge_text or None, prompt used)\n",
    "    \"\"\"\n",
    "    nudge_config = config[\"nudge\"]\n",
    "\n",
    "    # Format previous entries for context\n",
    "    prev_entries_data = None\n",
    "    if previous_entries:\n",
    "        prev_entries_data = [\n",
    "            {\"date\": e.initial_entry.date, \"content\": e.initial_entry.content}\n",
    "            for e in previous_entries[-3:]  # Last 3 entries for context\n",
    "        ]\n",
    "\n",
    "    prompt = nudge_generation_prompt.render(\n",
    "        entry_content=entry.content,\n",
    "        entry_date=entry.date,\n",
    "        nudge_category=category,\n",
    "        previous_entries=prev_entries_data,\n",
    "        min_words=nudge_config[\"min_words\"],\n",
    "        max_words=nudge_config[\"max_words\"],\n",
    "    )\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=NUDGE_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        data = json.loads(raw_json)\n",
    "        nudge_text = data.get(\"nudge_text\", \"\").strip()\n",
    "\n",
    "        # Validation: check word count\n",
    "        word_count = count_words(nudge_text)\n",
    "        if (\n",
    "            word_count < nudge_config[\"min_words\"]\n",
    "            or word_count > nudge_config[\"max_words\"]\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        return nudge_text, prompt\n",
    "\n",
    "    return None, prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nudge Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_response_mode(config: dict) -> str:\n",
    "    \"\"\"Select a response mode based on configured weights.\"\"\"\n",
    "    modes = config[\"nudge\"][\"response_modes\"]\n",
    "    weights = {m[\"mode\"]: m[\"weight\"] for m in modes}\n",
    "    return weighted_choice(weights)\n",
    "\n",
    "\n",
    "async def generate_nudge_response(\n",
    "    persona: Persona,\n",
    "    entry: JournalEntry,\n",
    "    nudge_text: str,\n",
    "    config: dict,\n",
    "    max_attempts: int = 2,\n",
    ") -> tuple[JournalTurn | None, str, str]:\n",
    "    \"\"\"Generate a response to a nudge.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (JournalTurn or None, prompt used, response_mode)\n",
    "    \"\"\"\n",
    "    response_mode = select_response_mode(config)\n",
    "\n",
    "    # Adjust word targets based on response mode\n",
    "    if response_mode == \"Deflecting/redirecting\":\n",
    "        min_words, max_words = 5, 30\n",
    "    elif response_mode == \"Revealing deeper thought\":\n",
    "        min_words, max_words = 20, 80\n",
    "    else:  # Answering directly\n",
    "        min_words, max_words = 15, 60\n",
    "\n",
    "    prompt = nudge_response_prompt.render(\n",
    "        name=persona.name,\n",
    "        age=persona.age,\n",
    "        profession=persona.profession,\n",
    "        culture=persona.culture,\n",
    "        bio=persona.bio,\n",
    "        entry_content=entry.content,\n",
    "        nudge_text=nudge_text,\n",
    "        response_mode=response_mode,\n",
    "        min_words=min_words,\n",
    "        max_words=max_words,\n",
    "    )\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=NUDGE_RESPONSE_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        data = json.loads(raw_json)\n",
    "        content = data.get(\"content\", \"\").strip()\n",
    "\n",
    "        if content:\n",
    "            turn = JournalTurn(\n",
    "                date=entry.date,\n",
    "                content=content,\n",
    "                turn_type=\"nudge_response\",\n",
    "                responding_to_nudge=nudge_text,\n",
    "            )\n",
    "            return turn, prompt, response_mode\n",
    "\n",
    "    return None, prompt, response_mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversational Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ConversationalPipelineResult:\n",
    "    \"\"\"Complete results from one persona's conversational generation pipeline.\"\"\"\n",
    "\n",
    "    persona_id: int\n",
    "    persona: Persona | None\n",
    "    entries: list[ConversationalEntry]\n",
    "    persona_prompt: str\n",
    "    entry_prompts: list[str]\n",
    "    nudge_prompts: list[str] = field(default_factory=list)\n",
    "    response_prompts: list[str] = field(default_factory=list)\n",
    "    error: str | None = None\n",
    "\n",
    "\n",
    "async def create_random_persona(\n",
    "    config: dict, schwartz_config: dict, max_attempts: int = 2\n",
    ") -> tuple[Persona | None, str]:\n",
    "    \"\"\"Generate a random persona with Schwartz values shown through life circumstances.\"\"\"\n",
    "    age = random.choice(config[\"personas\"][\"age_ranges\"])\n",
    "    prof = random.choice(config[\"personas\"][\"professions\"])\n",
    "    cult = random.choice(config[\"personas\"][\"cultures\"])\n",
    "    num_values = random.choice([1, 2])\n",
    "    vals = random.sample(config[\"personas\"][\"schwartz_values\"], num_values)\n",
    "\n",
    "    # Build rich value context from the Schwartz elaborations\n",
    "    value_context = build_value_context(vals, schwartz_config)\n",
    "\n",
    "    prompt = persona_generation_prompt.render(\n",
    "        age=age,\n",
    "        profession=prof,\n",
    "        culture=cult,\n",
    "        values=vals,\n",
    "        value_context=value_context,\n",
    "        banned_terms=SCHWARTZ_BANNED_TERMS,\n",
    "    )\n",
    "\n",
    "    first_person_pattern = re.compile(r\"(?i)\\b(i|my|me)\\b\")\n",
    "    last_persona: Persona | None = None\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=PERSONA_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        data = json.loads(raw_json)\n",
    "        data[\"core_values\"] = vals  # Ensure correct values\n",
    "        persona = Persona(**data)\n",
    "        last_persona = persona\n",
    "\n",
    "        # Only validate banned terms and first-person usage\n",
    "        if BANNED_PATTERN.search(persona.bio) or first_person_pattern.search(\n",
    "            persona.bio\n",
    "        ):\n",
    "            continue\n",
    "        return persona, prompt\n",
    "\n",
    "    return last_persona, prompt\n",
    "\n",
    "\n",
    "async def generate_journal_entry(\n",
    "    persona: Persona,\n",
    "    config: dict,\n",
    "    date_str: str,\n",
    "    previous_entries: list[JournalEntry] | None = None,\n",
    "    max_attempts: int = 2,\n",
    ") -> tuple[tuple[JournalEntry, str, str, str] | None, str]:\n",
    "    \"\"\"Generate a journal entry for a persona on a given date.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of ((entry, tone, verbosity, reflection_mode) or None, prompt used)\n",
    "    \"\"\"\n",
    "    tone = random.choice(config[\"journal_entries\"][\"tones\"])\n",
    "    verbosity = random.choice(config[\"journal_entries\"][\"verbosity\"])\n",
    "    reflection_mode = random.choice(config[\"journal_entries\"][\"reflection_mode\"])\n",
    "    min_words, max_words, max_paragraphs = _verbosity_targets(verbosity)\n",
    "\n",
    "    # Format previous entries for the prompt\n",
    "    prev_entries_data = None\n",
    "    if previous_entries:\n",
    "        prev_entries_data = [\n",
    "            {\"date\": e.date, \"content\": e.content} for e in previous_entries\n",
    "        ]\n",
    "\n",
    "    prompt = journal_entry_prompt.render(\n",
    "        name=persona.name,\n",
    "        age=persona.age,\n",
    "        profession=persona.profession,\n",
    "        culture=persona.culture,\n",
    "        bio=persona.bio,\n",
    "        date=date_str,\n",
    "        tone=tone,\n",
    "        verbosity=verbosity,\n",
    "        min_words=min_words,\n",
    "        max_words=max_words,\n",
    "        max_paragraphs=max_paragraphs,\n",
    "        reflection_mode=reflection_mode,\n",
    "        previous_entries=prev_entries_data,\n",
    "    )\n",
    "\n",
    "    last_entry: JournalEntry | None = None\n",
    "\n",
    "    for _ in range(max_attempts):\n",
    "        raw_json = await generate_completion(\n",
    "            prompt, response_format=JOURNAL_ENTRY_RESPONSE_FORMAT\n",
    "        )\n",
    "        if not raw_json:\n",
    "            continue\n",
    "\n",
    "        entry = JournalEntry(**json.loads(raw_json))\n",
    "        last_entry = entry\n",
    "\n",
    "        # Only validate banned terms (prevent label leakage)\n",
    "        if not BANNED_PATTERN.search(entry.content):\n",
    "            return (entry, tone, verbosity, reflection_mode), prompt\n",
    "\n",
    "    if last_entry:\n",
    "        return (last_entry, tone, verbosity, reflection_mode), prompt\n",
    "    return None, prompt\n",
    "\n",
    "\n",
    "async def generate_conversational_entry(\n",
    "    persona: Persona,\n",
    "    config: dict,\n",
    "    date_str: str,\n",
    "    previous_entries: list[ConversationalEntry] | None = None,\n",
    ") -> tuple[ConversationalEntry | None, str, str | None, str | None]:\n",
    "    \"\"\"Generate entry, decide on nudge, optionally generate response.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (ConversationalEntry or None, entry_prompt, nudge_prompt, response_prompt)\n",
    "    \"\"\"\n",
    "    # Step 1: Generate initial entry\n",
    "    prev_journal_entries = [e.initial_entry for e in (previous_entries or [])]\n",
    "    entry_result, entry_prompt = await generate_journal_entry(\n",
    "        persona, config, date_str, previous_entries=prev_journal_entries\n",
    "    )\n",
    "\n",
    "    if not entry_result:\n",
    "        return None, entry_prompt, None, None\n",
    "\n",
    "    entry, tone, verbosity, reflection_mode = entry_result\n",
    "\n",
    "    # Step 2: Decide whether to nudge (LLM-based semantic classification)\n",
    "    # No synthetic metadata (tone, verbosity, reflection_mode) is passed\n",
    "    should_nudge, nudge_category, trigger_reason = await decide_nudge_llm(\n",
    "        entry=entry,\n",
    "        previous_entries=previous_entries,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    nudge_result = None\n",
    "    response = None\n",
    "    nudge_prompt = None\n",
    "    response_prompt = None\n",
    "\n",
    "    if should_nudge and nudge_category:\n",
    "        # Step 3: Generate nudge\n",
    "        nudge_text, nudge_prompt = await generate_nudge(\n",
    "            entry=entry,\n",
    "            category=nudge_category,\n",
    "            previous_entries=previous_entries,\n",
    "            config=config,\n",
    "        )\n",
    "\n",
    "        if nudge_text:\n",
    "            nudge_result = NudgeResult(\n",
    "                nudge_text=nudge_text,\n",
    "                nudge_category=nudge_category,\n",
    "                trigger_reason=trigger_reason or \"\",\n",
    "            )\n",
    "\n",
    "            # Step 4: Decide if persona responds (probabilistic)\n",
    "            if random.random() < config[\"nudge\"][\"response_probability\"]:\n",
    "                (\n",
    "                    response,\n",
    "                    response_prompt,\n",
    "                    response_mode,\n",
    "                ) = await generate_nudge_response(\n",
    "                    persona=persona, entry=entry, nudge_text=nudge_text, config=config\n",
    "                )\n",
    "                if response:\n",
    "                    nudge_result.was_responded_to = True\n",
    "\n",
    "    return (\n",
    "        ConversationalEntry(\n",
    "            initial_entry=entry,\n",
    "            nudge=nudge_result,\n",
    "            response=response,\n",
    "            tone=tone,\n",
    "            verbosity=verbosity,\n",
    "            reflection_mode=reflection_mode,\n",
    "        ),\n",
    "        entry_prompt,\n",
    "        nudge_prompt,\n",
    "        response_prompt,\n",
    "    )\n",
    "\n",
    "\n",
    "async def generate_conversational_pipeline(\n",
    "    persona_id: int,\n",
    "    config: dict,\n",
    "    schwartz_config: dict,\n",
    "    num_entries: int = 3,\n",
    "    start_date: str = \"2023-10-27\",\n",
    ") -> ConversationalPipelineResult:\n",
    "    \"\"\"Generate one persona and all their conversational journal entries.\"\"\"\n",
    "    entry_prompts: list[str] = []\n",
    "    nudge_prompts: list[str] = []\n",
    "    response_prompts: list[str] = []\n",
    "    entries: list[ConversationalEntry] = []\n",
    "\n",
    "    # 1. Generate persona\n",
    "    persona, persona_prompt = await create_random_persona(config, schwartz_config)\n",
    "\n",
    "    if not persona:\n",
    "        return ConversationalPipelineResult(\n",
    "            persona_id=persona_id,\n",
    "            persona=None,\n",
    "            entries=[],\n",
    "            persona_prompt=persona_prompt,\n",
    "            entry_prompts=[],\n",
    "            error=\"Failed to generate persona\",\n",
    "        )\n",
    "\n",
    "    # 2. Generate conversational entries sequentially\n",
    "    dates = generate_date_sequence(start_date, num_entries)\n",
    "\n",
    "    for date_str in dates:\n",
    "        (\n",
    "            conv_entry,\n",
    "            entry_prompt,\n",
    "            nudge_prompt,\n",
    "            response_prompt,\n",
    "        ) = await generate_conversational_entry(\n",
    "            persona, config, date_str, previous_entries=entries\n",
    "        )\n",
    "        entry_prompts.append(entry_prompt)\n",
    "        if nudge_prompt:\n",
    "            nudge_prompts.append(nudge_prompt)\n",
    "        if response_prompt:\n",
    "            response_prompts.append(response_prompt)\n",
    "\n",
    "        if conv_entry:\n",
    "            entries.append(conv_entry)\n",
    "\n",
    "    return ConversationalPipelineResult(\n",
    "        persona_id=persona_id,\n",
    "        persona=persona,\n",
    "        entries=entries,\n",
    "        persona_prompt=persona_prompt,\n",
    "        entry_prompts=entry_prompts,\n",
    "        nudge_prompts=nudge_prompts,\n",
    "        response_prompts=response_prompts,\n",
    "        error=None,\n",
    "    )\n",
    "\n",
    "\n",
    "async def run_parallel_conversational_personas(\n",
    "    num_personas: int,\n",
    "    config: dict,\n",
    "    schwartz_config: dict,\n",
    "    num_entries: int = 3,\n",
    "    start_date: str = \"2023-10-27\",\n",
    ") -> list[ConversationalPipelineResult | Exception]:\n",
    "    \"\"\"Run multiple conversational persona pipelines in parallel.\"\"\"\n",
    "    tasks = [\n",
    "        generate_conversational_pipeline(\n",
    "            i + 1, config, schwartz_config, num_entries, start_date\n",
    "        )\n",
    "        for i in range(num_personas)\n",
    "    ]\n",
    "\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Logging System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_dir() -> Path:\n",
    "    \"\"\"Create and return a timestamped log directory.\"\"\"\n",
    "    base_dir = Path(\"logs/synthetic_data\")\n",
    "    if not base_dir.exists():\n",
    "        base_dir = Path(\"../logs/synthetic_data\")\n",
    "    base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    log_dir = base_dir / timestamp\n",
    "    log_dir.mkdir(exist_ok=True)\n",
    "    return log_dir\n",
    "\n",
    "\n",
    "def write_config_log(\n",
    "    log_dir: Path, config: dict, num_personas: int, num_entries: int\n",
    ") -> None:\n",
    "    \"\"\"Write config.md with run parameters.\"\"\"\n",
    "    content = f\"\"\"# Run Configuration\n",
    "\n",
    "**Timestamp**: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "**Notebook**: journal_nudge.ipynb\n",
    "\n",
    "## Persona Generation\n",
    "- Num personas: {num_personas}\n",
    "- Entries per persona: {num_entries}\n",
    "\n",
    "## Nudge Settings\n",
    "- Decision method: LLM-based classification (prompts/nudge_decision.yaml)\n",
    "- Response probability: {config[\"nudge\"][\"response_probability\"]}\n",
    "\n",
    "## Model Settings\n",
    "- Model: {MODEL_NAME}\n",
    "- Reasoning effort: {DEFAULT_REASONING_EFFORT}\n",
    "\"\"\"\n",
    "    (log_dir / \"config.md\").write_text(content)\n",
    "\n",
    "\n",
    "def write_persona_log(log_dir: Path, result: ConversationalPipelineResult) -> None:\n",
    "    \"\"\"Write persona_XXX.md with all entries and nudges.\"\"\"\n",
    "    if not result.persona:\n",
    "        return\n",
    "\n",
    "    p = result.persona\n",
    "    lines = [\n",
    "        f\"# Persona {result.persona_id:03d}: {p.name}\",\n",
    "        \"\",\n",
    "        \"## Profile\",\n",
    "        f\"- Age: {p.age}\",\n",
    "        f\"- Profession: {p.profession}\",\n",
    "        f\"- Culture: {p.culture}\",\n",
    "        f\"- Core Values: {', '.join(p.core_values)}\",\n",
    "        f\"- Bio: {p.bio}\",\n",
    "        \"\",\n",
    "        \"---\",\n",
    "    ]\n",
    "\n",
    "    for i, entry in enumerate(result.entries, 1):\n",
    "        lines.extend(\n",
    "            [\n",
    "                \"\",\n",
    "                f\"## Entry {i} - {entry.initial_entry.date}\",\n",
    "                \"\",\n",
    "                \"### Initial Entry\",\n",
    "                f\"**Tone**: {entry.tone} | **Verbosity**: {entry.verbosity} | **Reflection Mode**: {entry.reflection_mode}\",\n",
    "                \"\",\n",
    "                entry.initial_entry.content,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if entry.nudge:\n",
    "            lines.extend(\n",
    "                [\n",
    "                    \"\",\n",
    "                    f\"### Nudge ({entry.nudge.nudge_category.replace('_', ' ').title()})\",\n",
    "                    f\"**Trigger**: {entry.nudge.trigger_reason}\",\n",
    "                    \"\",\n",
    "                    f'\"{entry.nudge.nudge_text}\"',\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if entry.response:\n",
    "                lines.extend(\n",
    "                    [\n",
    "                        \"\",\n",
    "                        \"### Response\",\n",
    "                        \"\",\n",
    "                        entry.response.content,\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                lines.append(\"\\n*(No response)*\")\n",
    "        else:\n",
    "            lines.append(\"\\n*(No nudge for this entry)*\")\n",
    "\n",
    "        lines.extend([\"\", \"---\"])\n",
    "\n",
    "    (log_dir / f\"persona_{result.persona_id:03d}.md\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "def write_prompts_log(\n",
    "    log_dir: Path, results: list[ConversationalPipelineResult]\n",
    ") -> None:\n",
    "    \"\"\"Write prompts.md with all LLM prompts.\"\"\"\n",
    "    lines = [\"# Prompts Log\", \"\"]\n",
    "\n",
    "    for result in results:\n",
    "        if isinstance(result, Exception) or not result.persona:\n",
    "            continue\n",
    "\n",
    "        lines.extend(\n",
    "            [\n",
    "                f\"## Persona {result.persona_id:03d}: {result.persona.name}\",\n",
    "                \"\",\n",
    "                \"### Persona Generation Prompt\",\n",
    "                \"```\",\n",
    "                result.persona_prompt,\n",
    "                \"```\",\n",
    "                \"\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        for i, prompt in enumerate(result.entry_prompts, 1):\n",
    "            lines.extend(\n",
    "                [\n",
    "                    f\"### Entry {i} - Initial Entry Prompt\",\n",
    "                    \"```\",\n",
    "                    prompt,\n",
    "                    \"```\",\n",
    "                    \"\",\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        if result.nudge_prompts:\n",
    "            for i, prompt in enumerate(result.nudge_prompts, 1):\n",
    "                lines.extend(\n",
    "                    [\n",
    "                        f\"### Nudge Prompt {i}\",\n",
    "                        \"```\",\n",
    "                        prompt,\n",
    "                        \"```\",\n",
    "                        \"\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        if result.response_prompts:\n",
    "            for i, prompt in enumerate(result.response_prompts, 1):\n",
    "                lines.extend(\n",
    "                    [\n",
    "                        f\"### Response Prompt {i}\",\n",
    "                        \"```\",\n",
    "                        prompt,\n",
    "                        \"```\",\n",
    "                        \"\",\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "        lines.append(\"---\\n\")\n",
    "\n",
    "    (log_dir / \"prompts.md\").write_text(\"\\n\".join(lines))\n",
    "\n",
    "\n",
    "def save_run_logs(\n",
    "    results: list[ConversationalPipelineResult | Exception],\n",
    "    config: dict,\n",
    "    num_personas: int,\n",
    "    num_entries: int,\n",
    ") -> Path:\n",
    "    \"\"\"Save all logs for a run.\n",
    "\n",
    "    Returns:\n",
    "        Path to the log directory\n",
    "    \"\"\"\n",
    "    log_dir = get_log_dir()\n",
    "\n",
    "    # Filter successful results\n",
    "    successful = [\n",
    "        r for r in results if isinstance(r, ConversationalPipelineResult) and r.persona\n",
    "    ]\n",
    "\n",
    "    write_config_log(log_dir, config, num_personas, num_entries)\n",
    "\n",
    "    for result in successful:\n",
    "        write_persona_log(log_dir, result)\n",
    "\n",
    "    write_prompts_log(log_dir, successful)\n",
    "\n",
    "    print(f\"Logs saved to: {log_dir}\")\n",
    "    return log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_conversational_results(\n",
    "    result: ConversationalPipelineResult | Exception,\n",
    ") -> None:\n",
    "    \"\"\"Display all outputs for one persona.\"\"\"\n",
    "    if isinstance(result, Exception):\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"PERSONA FAILED WITH EXCEPTION:\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "        print(f\"{type(result).__name__}: {result}\")\n",
    "        print(f\"{'=' * 80}\\n\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"PERSONA {result.persona_id}\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "    if result.error:\n",
    "        print(f\"\\nError: {result.error}\")\n",
    "        return\n",
    "\n",
    "    # Persona details\n",
    "    p = result.persona\n",
    "    print(f\"\\n## Generated Persona: {p.name}\")\n",
    "    print(f\"Age: {p.age} | Profession: {p.profession} | Culture: {p.culture}\")\n",
    "    print(f\"Values: {', '.join(p.core_values)}\")\n",
    "    print(f\"Bio: {p.bio}\")\n",
    "\n",
    "    # Entries with nudges\n",
    "    for i, entry in enumerate(result.entries, 1):\n",
    "        print(f\"\\n{'─' * 40}\")\n",
    "        print(f\"### Entry {i}: {entry.initial_entry.date}\")\n",
    "        print(\n",
    "            f\"Tone: {entry.tone} | Verbosity: {entry.verbosity} | Mode: {entry.reflection_mode}\"\n",
    "        )\n",
    "        print(f\"\\n**Initial Entry:**\")\n",
    "        print(entry.initial_entry.content)\n",
    "\n",
    "        if entry.nudge:\n",
    "            print(f\"\\n**Nudge ({entry.nudge.nudge_category}):**\")\n",
    "            print(f\"Trigger: {entry.nudge.trigger_reason}\")\n",
    "            print(f'\"{entry.nudge.nudge_text}\"')\n",
    "\n",
    "            if entry.response:\n",
    "                print(f\"\\n**Response:**\")\n",
    "                print(entry.response.content)\n",
    "            else:\n",
    "                print(\"\\n*(No response)*\")\n",
    "        else:\n",
    "            print(\"\\n*(No nudge)*\")\n",
    "\n",
    "    # Summary stats\n",
    "    nudge_count = sum(1 for e in result.entries if e.nudge)\n",
    "    response_count = sum(1 for e in result.entries if e.nudge and e.response)\n",
    "    print(f\"\\n{'─' * 40}\")\n",
    "    print(f\"### Summary for {p.name}\")\n",
    "    print(f\"Total entries: {len(result.entries)}\")\n",
    "    print(f\"Nudges given: {nudge_count}\")\n",
    "    print(f\"Responses received: {response_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 3 personas with conversational journaling...\n",
      "Each persona will have 5 entries with potential nudges.\n",
      "Model: gpt-5-mini-2025-08-07 | Reasoning: high\n",
      "Start date: 2025-10-25\n",
      "Nudge decision: LLM-based classification (prompts/nudge_decision.yaml)\n",
      "Response probability: 0.7\n",
      "\n",
      "\n",
      "================================================================================\n",
      "PERSONA 1\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Neha Kapoor\n",
      "Age: 48 | Profession: Parent (Stay-at-home) | Culture: South Asian\n",
      "Values: Self-Direction\n",
      "Bio: Neha Kapoor is 48 and a stay-at-home parent who left a ten-year brand strategist role at an advertising agency to run an online upcycled-sari shop and design project-based, hands-on learning for her two children. She organizes neighborhood science days, runs weekend coding and textile workshops from her living room, and spent last year teaching herself product photography—choices that keep the household flexible but draw criticism from relatives and a mother-in-law who try to enroll the children in the local school's rigid timetable without discussing it with her. Money is tighter than before and she sometimes worries about long-term savings, but she finds concrete satisfaction finishing a new lesson plan or selling a handmade collection she photographed, and regularly defends the way she has reorganized the family's days.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Exhausted | Verbosity: Short (1-3 sentences) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Said no to my mother-in-law without arguing—packed the sold upcycled-sari blouse, set the kids on a messy textile project, and shot product photos while chai cooled on the sill. I'm exhausted, but for a few minutes it felt quietly right.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-11-04\n",
      "Tone: Exhausted | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "My phone kept buzzing in the jar where I toss receipts; seven messages by eight-thirty. I answered between stirring the dal—two buyers asking measurements, the neighbor asking if Rohan could come over while she ran to the market. Asha held up her laptop and declared the loop was broken; I told her to step through each line and then fiddled with the camera exposure for a sari swatch until the gold didn't wash out. Saas texted about a school form; I typed \"we'll discuss\" and went on.\n",
      "\n",
      "Made a quick lesson plan for Saturday's textile table—three stations, short prompts, an outcomes card for each because long slides bore me. Folded labels for scarves, taped them to a cardboard board, and lined up samples by color. Checked the bank app out of habit; smaller number than last month, closed it. A tiny payment came through for a set of upcycled scarves and for a minute I let the small good land.\n",
      "\n",
      "The kids watched a science clip; I sorted threads—navy, marigold, silver that kept fraying—and made a note on the fridge of things to collect for neighborhood science day. Charged the camera, wiped glue from my thumb, and scored a tiny fraction of the old blouse pattern to keep for templates. The list is still under the magnet, the kettle will be forgotten until morning, and I'm too tired to make sense of tomorrow's schedule.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-13\n",
      "Tone: Defensive | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Kettle boiled over while I was stapling price tags and I let the glue dry on my thumb. Asha leaned across the table with the laptop and mouthed, 'Off by one,' while Rohan, threads in his hair, swore he'd finish his kantha sampler before he answered the neighbor. Saas sent another message about the school's form—no discussion, just instructions—so I put the phone face down and sealed the parcel.\n",
      "\n",
      "I peeked at the bank app by reflex; smaller than last month, but three tiny payments for scarves and a blouse came through and that low little landing made enough space to breathe. Adjusted camera exposure until the zari held its color, taught myself a cropping shortcut, wiped glue on my kurta hem, and wrote the price again on a folded tag. The dal cooled on the stove and I still kept moving.\n",
      "\n",
      "Folded three outcome cards for Saturday's textile table because long slides make the kids glaze over; labels in my cramped hand, simple prompts that actually get them making. Saas's form sits on top of the fridge; I'll call her after dinner and explain—again—that enrolling the children without talking to me isn't acceptable. This life is a thousand small decisions; I guard them, quietly, every day.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Includes ongoing conflict with 'Saas' about enrolling children without discussion, indicating unresolved tension needing follow-up.\n",
      "\"Off by one—what was that about?\"\n",
      "\n",
      "**Response:**\n",
      "She was pointing out my labels were one spot off, so prices sat on the wrong pieces. I corrected them quickly.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-19\n",
      "Tone: Exhausted | Verbosity: Medium (1-2 paragraphs) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Saas called and said she would take care of the school form; I was threading a needle through a sari border, glue and gold dust on my thumb, camera battery blinking red. Asha was leaning across with the laptop—'off by one'—and Rohan kept tugging his kantha sampler at me. The parcel needed sealing, the chai cooled, and instead of arguing I took a photo of the filled form, typed 'okay' and sent it. I packed the scarves, stapled the price tags, and walked away with my kurta hem sticky.\n",
      "\n",
      "Now the house feels quieter in the wrong way. The sampler sits half-done, the labels are stacked, and Saas's message buzzes in the corner of my mind. I haven't called to change it; the decision lies there, small and present, like a stubborn knot in a stitch. I go on moving—iron the hems, charge the camera—but the unease sits with the price tags.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Avoided confronting mother-in-law; unresolved decision creates persistent unease around price tags.\n",
      "\"Are you going to call Saas?\"\n",
      "\n",
      "*(No response)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-29\n",
      "Tone: Brief and factual | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "Chai went cold on the counter because I was fussing with exposure again, trying to keep the zari from blowing out. Asha hovered with the laptop - \"less highlight\" - and Rohan, mouth stained from the biscuit, kept tugging at his kantha sampler. The phone buzzed in the glass jar: two buyers asking measurements, the neighbor asking if Rohan could fetch her bag. I answered in fragments between clicks.\n",
      "\n",
      "Sealed a scarf, stapled price tags, taped folded labels to a board, packed three parcels and put them by the door. Charged the camera, edited photos fast so the light would match the sari, checked the bank app because habit; the number is tight but a small payment landed and I allowed myself to notice it. Wiped glue off my thumb on the hem of my kurta and made outcome cards for Saturday - short prompts, three stations - so the kids won't drift.\n",
      "\n",
      "Saas sent a message about the school form; I read it, set the phone down and didn't call. No argument today, no decision - just the form on the fridge that I will deal with later. The day moved on: dal simmering, tape in one hand, children at the table, and me crossing items off the list.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Neha Kapoor\n",
      "Total entries: 5\n",
      "Nudges given: 2\n",
      "Responses received: 1\n",
      "\n",
      "================================================================================\n",
      "PERSONA 2\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Anita Kapoor\n",
      "Age: 49 | Profession: Software Engineer | Culture: South Asian\n",
      "Values: Self-Direction, Stimulation\n",
      "Bio: Anita Kapoor left a stable senior role at a multinational tech firm six years ago to consult for early-stage startups and maintain an open-source machine-learning toolkit she developed, choosing project-based work over a predictable corporate track. She schedules three-month blocks for emergency debugging contracts, fits Himalayan trekking trips between client sprints, and has turned down promotions that would have put her under strict reporting and process requirements. Those choices have produced financial ups and downs and tension with family members who preferred a steadier path, but she judges success by the new systems she builds from scratch and the next unexpected challenge she signs up for.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Brief and factual | Verbosity: Short (1-3 sentences) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Clicked 'accept' on the consultant agreement that keeps any improvements closed for 90 days so the demo could happen tomorrow; pushed the tweak to a private branch and marked a TODO to upstream later. Made chai and lied to Maa about how steady the work is.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Shows ethical/work conflict and concealment—accepted restrictive agreement and lied to Maa about stability.\n",
      "\"Why lie to Maa about steady work?\"\n",
      "\n",
      "**Response:**\n",
      "Because Maa worries and I was tired; easier to spare her worry and dodge the 'get a proper job' lecture tonight. I'll explain later.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-10-28\n",
      "Tone: Stream of consciousness | Verbosity: Medium (1-2 paragraphs) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "—I pushed the minimal patch into the branch and closed the ticket, and when the founder pinged asking for 'one tiny change' that would've pulled another week of work, I typed a flat 'no' and a two-line plan for a paid follow-up. Sent it without hedging, scheduled the next sprint item, then muted the thread. No theater, just a boundary drawn.\n",
      "\n",
      "Made chai, stirred powdered masala because that's what's left, sat on the balcony while Maa banged the pressure cooker and argued with the neighbor about the meter. Didn't rehearse the answer again, didn't soften it. I finished the cup, pulled up the trek calendar, blocked a day. Small, ordinary, the exact quiet I mean to keep being.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-07\n",
      "Tone: Stream of consciousness | Verbosity: Short (1-3 sentences) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Agreed to demo with the half-baked feature and dropped a brittle flag so the pipeline wouldn't crash; pushed straight to main with a 'temp' commit, then told Maa the work is steady and pretended to enjoy the chai. It sits wrong.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Describes cutting corners and lying about status, expresses discomfort—unresolved ethical/work tension.\n",
      "\"Why'd you push straight to main?\"\n",
      "\n",
      "**Response:**\n",
      "Impatience and pride. Not thinking. Anyway — which trek shall I book?\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-15\n",
      "Tone: Self-reflective | Verbosity: Medium (1-2 paragraphs) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Telling Maa 'I'm leaving on Sunday' and not saying 'if it's okay' or 'I'll only be gone a little'—that was small. She folded her dupatta, listed what I'd forget in the kitchen, said the neighbor will come to check the meter. I didn't counter with justifications. I told her I'll pack dal, turned the pressure cooker off, and kept pouring chai. She grunted; the tension didn't swell into a negotiation.\n",
      "\n",
      "Later, when the founder messaged asking for another 'tiny' change, I typed a one-line scope for paid follow-up and hit send without hemming. Made a second cup of masala chai, opened the trek calendar and blocked the days. No fanfare. It landed as a small, ordinary quiet.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-20\n",
      "Tone: Brief and factual | Verbosity: Long (Detailed reflection) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Release notes for the demo of the open-source ML toolkit landed in the investor Slack and the founder put their name in the 'engineering' header. I opened a reply, started a one-line correction with the PR number and a co-authored line, deleted it, and left the thread. The post stayed unchanged. I shut the laptop, turned off the pressure cooker whistle, told Maa I'd sort the electrician later, and poured a cup of chai I didn't drink.\n",
      "\n",
      "An hour later the investor digest hit my inbox and the founder's assistant thanked the team for the 'fast delivery.' I didn't forward the draft I had deleted. I tagged the release in git, archived the feature branch, and set myself a calendar block for the trek. I folded my dupattā, packed dal into a small pouch, and didn't leave a visible note about attribution anywhere obvious.\n",
      "\n",
      "It sits wrong. The public record reads one way and the commits tell another piece. There are no angry emails, no immediate failures—just a small, unstated omission sitting where I can see it when I open the repo. It sits wrong.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Unresolved conflict about attribution and omitted correction; clear discomfort and moral tension remain.\n",
      "\"Why didn't you forward the draft?\"\n",
      "\n",
      "**Response:**\n",
      "Maybe tired. Not worth the fuss. Mountains and silence felt more necessary than a footnote.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Anita Kapoor\n",
      "Total entries: 5\n",
      "Nudges given: 3\n",
      "Responses received: 3\n",
      "\n",
      "================================================================================\n",
      "PERSONA 3\n",
      "================================================================================\n",
      "\n",
      "## Generated Persona: Mark Bennett\n",
      "Age: 48 | Profession: Software Engineer | Culture: North American\n",
      "Values: Tradition, Conformity\n",
      "Bio: Mark Bennett is a 48-year-old software engineer in Cleveland who has worked at the same mid-size payment-processing company for 18 years and still runs the Sunday database reconciliation script he inherited from his mentor to ensure month-end reports come out the same way each month. He keeps his mother's Thanksgiving recipes in a worn binder, hosts extended family at his parents' house for holidays, and is teaching his teenage daughter to set the table and carve the roast because he fears those rituals will vanish as cousins move across the country. At work he follows the team's coding standards and release checklist without fail and usually keeps objections to himself in meetings, which leaves him frustrated when leadership pushes new workflows that would upend long-standing processes; he wants to pass on the practices he learned and keep both family and team routines steady.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 1: 2025-10-25\n",
      "Tone: Exhausted | Verbosity: Long (Detailed reflection) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "I clicked 'merge' with the final verification unchecked. In the meeting they were impatient, the product folks kept repeating 'ship now' and someone in the corner joked about month-end. I said nothing when they suggested skipping the last reconcile step. I told myself I'd finish the check afterward, that it was a small shortcut to keep the release on time. The commit went live.\n",
      "\n",
      "I've run the Sunday database reconciliation script my mentor handed me for years; it's the thing I do to make sure the month-end reports line up. I obey the checklist normally; I keep objections to myself in meetings. This time I filed the objection, muttered 'okay,' and left the assert disabled. It felt easier at the time. People left the room relieved. I sat at my desk with the monitor glow and pretended I wasn't thinking about it.\n",
      "\n",
      "Now my coffee is cold, the worn Thanksgiving binder is open because my daughter wanted to help with table settings, and that small unease is still there. Nothing exploded, nothing overnight, just a quiet wrongness that won't make itself go away. I'm exhausted.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Clear moral conflict and unresolved guilt about skipping safety step; emotional tension remains.\n",
      "\"Why did you leave the final verification unchecked?\"\n",
      "\n",
      "**Response:**\n",
      "I avoided the conflict — easier to nod and let it go than be the blocker. Fatigue and wanting the meeting to end won out over doing the boring, necessary work.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 2: 2025-11-01\n",
      "Tone: Exhausted | Verbosity: Short (1-3 sentences) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "Shoulders tight, coffee cold, I re-enabled the assert in the repo, ran the Sunday reconciliation, fixed the off-by-one, and pushed a tiny commit with a note in the channel saying what I changed. Nobody made a fuss; I didn't grandstand—just did the thing my mentor taught me.\n",
      "\n",
      "**Nudge (tension_surfacing):**\n",
      "Trigger: Expresses restraint and lingering stress; downplays feelings and hints at unresolved interpersonal tension.\n",
      "\"Why were your shoulders tight?\"\n",
      "\n",
      "**Response:**\n",
      "Bracing for someone to freak if anything slipped, and the weight of keeping things steady. Habit of fixing quietly instead of arguing—so I carry it on my own.\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 3: 2025-11-07\n",
      "Tone: Emotional/Venting | Verbosity: Short (1-3 sentences) | Mode: Unsettled\n",
      "\n",
      "**Initial Entry:**\n",
      "Mom's binder open on the kitchen counter, my daughter tugging my sleeve and asking me to show her how to carve the roast. I told her 'not tonight, later' because of one more deploy to babysit, and she nodded. That quiet nod has been with me all evening.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 4: 2025-11-17\n",
      "Tone: Stream of consciousness | Verbosity: Long (Detailed reflection) | Mode: Neutral\n",
      "\n",
      "**Initial Entry:**\n",
      "My mug had gone cold on the left side of the desk while I skimmed the PRs—tiny comments rolling in, the usual 'LGTM' and a couple of flagged edge cases. Standup was five minutes of 'on schedule' and smiles; I kept the pushback to myself again, not worth the thirty-second back-and-forth this week. Between meetings I kicked off the reconciliation script just to be methodical; it finishes, I glance at the log, stamp it as done, carry on.\n",
      "\n",
      "Home smelled like onions and something roasting, Mom's recipe binder lay on the counter with a few pages bookmarked in an oily way that means it's been used. My daughter practiced folding napkins more carefully than last time and insisted on setting an extra fork 'just in case'—I showed her how to place it and how to steady the roast while I slice a small test piece. She likes to ask the same question about which knife is safe; I say 'start with the small serrated' and let her try on a roll.\n",
      "\n",
      "Later I left a short note in the team's channel: nothing out of the ordinary, numbers clean, moving on. Put the binder on its shelf, wiped the counter, checked tomorrow's calendar, and remembered to sign the permission slip for the science fair—small boxes ticked. No fireworks, no big decisions, just the steady little rituals that keep things predictable enough to sleep.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Entry 5: 2025-11-19\n",
      "Tone: Defensive | Verbosity: Medium (1-2 paragraphs) | Mode: Grounded\n",
      "\n",
      "**Initial Entry:**\n",
      "I said 'hold on' when someone skimmed past the reconciliation line like it was optional. Short, flat, I pointed to the check in the repo and where the assert lives. Nobody made a fuss; someone added it to the ticket and we moved on. Didn't make a scene, didn't lecture.\n",
      "\n",
      "At home my daughter asked for the knife. I set my hand over hers for the first slice, guided the motion, then let her take the next cuts. She steadied the roast, folded a napkin the way Mom taught me. Quiet, ordinary. I showed and stepped back.\n",
      "\n",
      "*(No nudge)*\n",
      "\n",
      "────────────────────────────────────────\n",
      "### Summary for Mark Bennett\n",
      "Total entries: 5\n",
      "Nudges given: 2\n",
      "Responses received: 2\n",
      "Logs saved to: ../logs/synthetic_data/2026-01-08_21-57-38\n",
      "\n",
      "================================================================================\n",
      "FINAL SUMMARY\n",
      "================================================================================\n",
      "Successfully generated: 3/3 personas\n",
      "Total entries: 15\n",
      "Total nudges given: 7\n",
      "Total responses: 6\n",
      "Response rate: 85.7%\n",
      "\n",
      "Logs saved to: ../logs/synthetic_data/2026-01-08_21-57-38\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "NUM_PERSONAS = 3\n",
    "NUM_ENTRIES = 5\n",
    "START_DATE = \"2025-10-25\"\n",
    "\n",
    "print(f\"Generating {NUM_PERSONAS} personas with conversational journaling...\")\n",
    "print(f\"Each persona will have {NUM_ENTRIES} entries with potential nudges.\")\n",
    "print(f\"Model: {MODEL_NAME} | Reasoning: {DEFAULT_REASONING_EFFORT}\")\n",
    "print(f\"Start date: {START_DATE}\")\n",
    "print(f\"Nudge decision: LLM-based classification (prompts/nudge_decision.yaml)\")\n",
    "print(f\"Response probability: {config['nudge']['response_probability']}\\n\")\n",
    "\n",
    "# Run all personas in parallel\n",
    "results = await run_parallel_conversational_personas(\n",
    "    num_personas=NUM_PERSONAS,\n",
    "    config=config,\n",
    "    schwartz_config=schwartz_config,\n",
    "    num_entries=NUM_ENTRIES,\n",
    "    start_date=START_DATE,\n",
    ")\n",
    "\n",
    "# Display results\n",
    "for result in results:\n",
    "    display_conversational_results(result)\n",
    "\n",
    "# Save logs\n",
    "successful_results = [\n",
    "    r for r in results if isinstance(r, ConversationalPipelineResult) and r.persona\n",
    "]\n",
    "log_dir = save_run_logs(results, config, NUM_PERSONAS, NUM_ENTRIES)\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(f\"FINAL SUMMARY\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"Successfully generated: {len(successful_results)}/{NUM_PERSONAS} personas\")\n",
    "\n",
    "total_entries = sum(len(r.entries) for r in successful_results)\n",
    "total_nudges = sum(sum(1 for e in r.entries if e.nudge) for r in successful_results)\n",
    "total_responses = sum(\n",
    "    sum(1 for e in r.entries if e.nudge and e.response) for r in successful_results\n",
    ")\n",
    "\n",
    "print(f\"Total entries: {total_entries}\")\n",
    "print(f\"Total nudges given: {total_nudges}\")\n",
    "print(f\"Total responses: {total_responses}\")\n",
    "if total_nudges > 0:\n",
    "    print(f\"Response rate: {total_responses / total_nudges:.1%}\")\n",
    "print(f\"\\nLogs saved to: {log_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twinkl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
